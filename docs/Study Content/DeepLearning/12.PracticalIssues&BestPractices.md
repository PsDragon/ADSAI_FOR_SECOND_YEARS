---
sort: 19
---

# Practical Issues & BestPractices

Read **Chapter 13** from Book - Deep Learning with Python, Second Edition

<img src="./assets/DL-Book.png" alt="Fairness" width="600">

From chapter 13, your primary objective is to get better understanding of Hyperparameter tuning. Model ensembling, Mixed-precision training
and Training Keras models on multiple GPUs or on a TPU are optional but very good to know. 

Make sure to apply the Hyperparameter tuning process in any/all of your CNNs projects. As usual take notes in the **_DL-notes.docx_** file in your **_Block C Microsoft Teams assignment_**. Clearly capture (screenshot) the various experiments you are implementing and their corresponding results with different hyperparameter settings.

The process of optimizing hyperparameters typically looks like this:

1. Choose a set of hyperparameters (automatically).

2. Build the corresponding model.

3. Fit it to your training data, and measure performance on the validation data.

4. Choose the next set of hyperparameters to try (automatically).

5. Repeat.

6. Eventually, measure performance on your test data.

The key to this process is the algorithm that analyzes the relationship between validation performance and various hyperparameter values to choose the next set of hyperparameters to evaluate. 

In addition to reading the book, refer to the code snippets from the book : [fchollet : chapter13_best-practices-for-the-real-world.ipynb](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter13_best-practices-for-the-real-world.ipynb)

For the rest of the day, feel free to catchup on your pending tasks from other days, or apply the keras-tuner to your creative brief use case, or dive into other self-guided topics of your interest.


## Literature

[Deep Learning with Python, Second Edition](https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/)