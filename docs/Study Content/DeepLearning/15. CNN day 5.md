---
sort: 15
---

# Week 4, Day 5, DataLab: Working with small datasets

This week you started building CNNs with Keras. Even if you develop a good CNN architecture, your model can perform poorly if you don't have enough data. Yesterday you learned how to deal with small datasets. In this DataLab you will apply what you learned to your creative brief dataset.

- [ ] Collect 50 images per class
- [ ] Use data augmentation
- [ ] Use transfer learning

In your reading assignment from yesterday, two ways to achieve transfer learning was described:

>1. Run the convolutional base over our dataset, record its output to a NumPy array on disk, and then use this data as input to a standalone, densely >connected classifier similar to those you saw in chapter 4 of this book. This solution is fast and cheap to run, because it only requires running the >convolutional base once for every input image, and the convolutional base is by far the most expensive part of the pipeline. But for the same reason, this >technique won’t allow us to use data augmentation.

>2. Extend the model we have (conv_base) by adding Dense layers on top, and run the whole thing from end to end on the input data. This will allow us to >use data augmentation, because every input image goes through the convolutional base every time it’s seen by the model. But for the same reason, this >technique is far more expensive than the first.

Use option 1 in this datalab, together with the MobileNet as your pretrained network.
