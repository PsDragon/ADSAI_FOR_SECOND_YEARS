---
sort: 19
---

# Week 5, Day 4: Model evaluation

By now, you have used the `evaluation` method from Keras many times.

```
model.evaluate(X_test, y_test)
```

But proper model evaluation is much more than that. Today you will broaden your model evaluation knowledge and tomorrow you will apply what you have learned to your creative brief dataset.

## 1. Metrics

https://arxiv.org/abs/2104.05642

## 2. Confidence Intervals

Let's say you reported 90% accuracy. This is called a point estimate in statistics. However, as the name suggests an estimate is not perfect. There is an error associated with it, in other words, uncertainty. We can report a interval instead of a single value to quantify this uncertainty. This is called a confidence interval. It is common to use a 95% confidence interval.

For example if we report 90% accuracy with a 95% Confidence Interval of (89.9â€“90.2), this means we are 95% confident that the true accuracy is between this interval. By true accuracy we mean the accuracy of the whole population.

https://machinelearningmastery.com/confidence-intervals-for-machine-learning/

## 3. Error analysis

Visualizing model errors is crucial for gaining insight into model performance.

## 4. Calibration

## 5. Baseline


