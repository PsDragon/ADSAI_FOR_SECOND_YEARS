---
sort: 5
---

# Neural Networks Concept Overview

Let’s take a look at the journey our inputs take inside of a neural network! By an input, we mean a data point from our dataset. Our input can have many different features, so in our input layer, each node represents a different input feature. For example, if we were working with a dataset of different types of food, some of our features might be size, shape, nutrition, etc., where the value for each of these features would be held in an input node.

Besides an input layer, our neural network has two other different types of layers:

1. Hidden layers are layers that come between the input layer and the output layer. They introduce complexity into our neural network and help with the learning process. You can have as many hidden layers as you want in a neural network (including zero of them).

2. The output layer is the final layer in our neural network. It produces the final result, so every neural network must have only one output layer.

Each layer in a neural network contains nodes. Nodes between each layer are connected by weights. These are the learning parameters of our neural network, determining the strength of the connection between each linked node.

The weighted sum between nodes and weights is calculated between each layer. For example, from our input layer, we take the weighted sum of the inputs and our weights with the following equation:

**_weighted_sum = (inputs ⋅ weight_transpose) + bias_**

We then apply an activation function to it.

**_Activation(weighted_sum)_**

The two formulas we have gone over take all the inputs through one layer of a neural network. Aside from the activation function, all of the transformations we have done so far are linear. Activation functions introduce nonlinearity in our learning model, creating more complexity during the learning process.

This is what makes activation functions important. A neural network with many hidden layers but no activation functions would just be a series of successive layers that would be no more effective or accurate than simple linear regression.

An activation function decides what is fired to the next neuron based on its calculation for the weighted sums. Various types of activation functions can be applied at each layer. The most popular one for hidden layers is ReLU.

<figure>
    <img src=".\assets\ReLU.svg" />
</figure>
<br>

Others commonly used, often for the output layer, are sigmoid and softmax. You will learn more about these functions as you use them later in this course.

<figure>
    <img src=".\assets\Sigmoid.svg" />
</figure>
<br>

## Bringing them all together
et’s bring all of these concepts together and see how they function in a neural network with one hidden layer. As you scroll over each section, you will see the inputs/weights/calculations associated with it and see how inputs get from the starting point and make their way to the end!

The process we have been going through is known as **forward propagation**. Inputs are moved forward from the input layer through the hidden layer(s) until they reach the output layer.

<figure>
    <img src=".\assets\forward-prop.png" />
</figure>
<br>

# Loss Function

We have seen how we get to an output! Now, what do we do with it? When a value is outputted, we calculate its error using a loss function. Our predicted values are compared with the actual values within the training data. 

<figure>
    <img src=".\assets\Loss_Function.gif" />
</figure>
<br>


There are two commonly used loss calculation formulas:

1. Mean squared error, which is most likely familiar to you if you have come across linear regression. This gif below shows how mean squared error is calculated for a line of best fit in linear regression.

<figure>
    <img src=".\assets\Loss.webp" />
</figure>
<br>

2. Cross-entropy loss, which is used for classification learning models rather than regression.
(_You will learn more about this as you use loss functions in your deep learning models._)


## Backpropagation

This all seems fine and dandy so far. However, what if our output values are inaccurate? Do we cry? Try harder next time? Well, we can do that, but the good news is that there is more to our deep learning models.

This is where backpropagation and gradient descent come into play. Forward propagation deals with feeding the input values through hidden layers to the final output layer. Backpropagation refers to the computation of gradients with an algorithm known as gradient descent. This algorithm continuously updates and refines the weights between neurons to minimize our loss function.

By gradient, we mean the rate of change with respect to the parameters of our loss function. From this, backpropagation determines how much each weight is contributing to the error in our loss function, and gradient descent will update our weight values accordingly to decrease this error.

This is a conceptual overview of backpropagation, for this course, we will not need this level of detailed understanding.

<!-- blank line -->
<figure class="video_container">
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U?controls=0" title="Back Propagation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<!-- blank line -->

## Gradient Descent

We have the overall process of backpropagation down! Now, let’s zoom in on what is happening during gradient descent.

If we think about the concept graphically, we want to look for the minimum point of our loss function because this will yield us the highest accuracy. If we start at a random point on our loss function, gradient descent will take “steps” in the “downhill direction” towards the negative gradient. The size of the “step” taken is dependent on our learning rate. Choosing the optimal learning rate is important because it affects both the efficiency and accuracy of our results.

The formula used with learning rate to update our weight parameters is the following:

_**parameter_new = parameter_old + learning_rate * gradient loss_function ( parameter_old ))**_

The learning rate we choose affects how large the “steps” our pointer takes when trying to optimize our error function. Initial intuition might indicate that you should choose a large learning rate; however, as shown above, this can lead you to overshoot the value we are looking for and cause a divergent search.

Now you might think that you should choose an incredibly small learning rate; however, if it is too small, it could cause your model to be unbearably inefficient or get stuck in a local minimum and never find the optimum value. It is a tricky game of finding the correct combination of efficiency and accuracy.

<figure>
    <img src=".\assets\Gradient_descent.gif" />
</figure>
<br>

<figure>
    <img src=".\assets\Gradient_descent (1).gif" />
</figure>
<br>

## Stochastic Gradient Descent

This leads us to the final point about gradient descent. In deep learning models, we are often dealing with extremely large datasets. Because of this, performing backpropagation and gradient descent calculations on all of our data may be inefficient and computationally exhaustive no matter what learning rate we choose.

To solve this problem, a variation of gradient descent known as Stochastic Gradient Descent (SGD) was developed. Let’s say we have 100,000 data points and 5 parameters. If we did 1000 iterations (also known as epochs in Deep Learning) we would end up with 100000⋅5⋅1000 = 500,000,000 computations. We do not want our computer to do that many computations on top of the rest of the learning model; it will take forever.

This is where SGD comes to play. Instead of performing gradient descent on our entire dataset, we pick out a random data point to use at each iteration. This cuts back on computation time immensely while still yielding accurate results.

<figure>
    <img src=".\assets\GD-Diagram.svg" />
</figure>
<br>

## More Variant of Gradient Descent with Adam

Just when you thought SDG solved all our problems, even more options come into the picture!

There are also other variants of gradient descent such as Adam optimization algorithm and mini-batch gradient descent. Adam is an adaptive learning algorithm that finds individual learning rates for each parameter. Mini-batch gradient descent is similar to SGD except instead of iterating on one data point at a time, we iterate on small batches of fixed size.

Adam optimizer’s ability to have an adaptive learning rate has made it an ideal variant of gradient descent and is commonly used in deep learning models. Mini-batch gradient descent was developed as an ideal trade-off between GD and SGD. Since mini-batch does not depend on just one training sample, it has a much smoother curve and is less affected by outliers and noisy data making it a more optimal algorithm for gradient descent than SGD.

These are just some quick notes! You can read more about Adam here and more about mini-batch here. Experts in deep learning are constantly coming up with ways to improve these algorithms to make them more efficient and accurate, so the ability to adapt and build upon what you learn as you dive into this domain will be key!

<figure>
    <img src=".\assets\Variants-of-Gradient Descent.png" />
</figure>
<br>