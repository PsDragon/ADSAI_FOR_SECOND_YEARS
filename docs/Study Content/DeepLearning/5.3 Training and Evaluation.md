---
sort: 9
---

# Training and Evaluation

Now that we built the model we are ready to train the model using the training data.

The following command trains a model instance my_model using training data my_data and training labels my_labels :

```python
my_model.fit(my_data, my_labels, epochs=50, batch_size=3, verbose=1)
model.fit() takes the following parameters:
```

1. my_data is the training data set.
2. my_labels are true labels for the training data points.
3. epochs refers to the number of cycles through the full training dataset. Since training of neural networks is an iterative process, you need multiple passes through data. Here we chose 50 epochs, but how do you pick a number of epochs? Well, it is hard to give one answer since it depends on your dataset. Amongst others, this is a hyperparameter that can be tuned — which we’ll cover later.
4. batch_size is the number of data points to work through before updating the model parameters. It is also a hyperparameter that can be tuned.
5. verbose = 1 will show you the progress bar of the training.

When the training is finalized, we use the trained model to predict values for samples that the training procedure haven’t seen: the test set.

The following commands evaluates the model instance my_model using the test data my_data and test labels my_labels:

```python
val_mse, val_mae = my_model.evaluate(my_data, my_labels, verbose = 0)
```

In our case, model.evaluate() returns the value for our chosen loss metrics (mse) and for an additional metrics (mae).

So what is the final result? We should get ~$3884.21. This means that on average we’re off with our prediction by around 3800 dollars. Is that a good result or a bad result?

Often you need an expert or domain knowledge to decide this. What is an acceptable error for the application? Is $3800 a big error when deciding on insurance charges? Can you do better and how? As you see, the process doesn’t stop here.