---
sort: 12
---

# Image Classification

Neural networks are perfectly suited for image classification: the task of finding the complex patterns in pixels necessary to map an image to its label. As a result, image classification is a common application of deep learning.

To do this, we will be using convolutional layers: layers designed to process image data by focusing on local relationships between features.

Pneumonia, the infection of lung tissue, is responsible for over two and a half million deaths worldwide. A radiologist’s diagnosis is often critical for the discovery and treatment of pneumonia. However, these doctors are often in short supply.

In this lesson, we will train a Convolutional Neural Network (CNN) to automatically classify chest X-rays, showcasing the potential for deep learning in medical domains.

# Preprocessing and augumenting Image Data

Our goal is to pass these X-ray images into our network, and to classify them according to their respective labels. At a high-level, this is very similar to our approach for classifying non-image data.

Now, our features are going to come from image pixels. Each image will be 256 pixels tall and 256 pixels wide, and each pixel has a value between 0 (black) - 255 (white).

<figure>
    <img src=".\assets\xray_diagram_labeled.png" />
</figure>
<br>

While loading and preprocessing image data can be a bit tricky, Keras provides us with a few tools to make the process less burdensome. Of these, the ImageDataGenerator class is the most critical. We can use ImageDataGenerators to load images from a file path, and to preprocess them. We can constuctor an ImageDataGenerator using the following code:

```python
my_image_data_generator = ImageDataGenerator()
```

Beyond just loading our images, the ImageDataGenerator can also preprocess our data. We do this by passing additional arguments to the constructor.

There are a few ways to preprocess image data, but we will focus on the most important step: pixel normalization. Because neural networks struggle with large integer values, we want to rescale our raw pixel values between 0 and 1. Our pixels have values in [0,255], so we can normalize pixels by dividing each pixel by 255.0.

We can also use our ImageDataGenerator for data augmentation: generating more data without collecting any new images. A common way to augment image data is to flip or randomly shift each image by small amounts. Because our dataset is only a few hundred images, we’ll also use the ImageDataGenerator to randomly shift images during training.

For example, we can define another ImageDataGenerator and set its vertical_flip parameter to be True.

```python
my_augmented_image_data_generator = ImageDataGenerator( vertical_flip = True )
```
 
If we use this ImageDataGenerator to load images, it will randomly flip some of those images upside down.

# Loading Image data

Now, we can use the ImageDataGenerator object that we just created to load and batch our data, using its .flow_from_directory() method.

Let’s consider each of its arguments:

- directory : A string that defines the path to the folder containing our training data.
- class_mode : How we should represent the labels in our data. “For example, we can set this to "categorical" to return our labels as one-hot arrays, with a 1 in the correct class slot.
- color_mode : Specifies the type of image. For example, we set this to "grayscale" for black and white images, or to "rgb" (Red-Green-Blue) for color images.
- target_size : A tuple specifying the height and width of our image. Every image in the directory will be resized into this shape.
- batch_size : The batch size of our data.

The resulting training_iterator variable is a DirectoryIterator object. We can pass this object directly to model.fit() to train our model on our training data.

For example, the following code creates a DirectoryIterator that loads images from "my_data_directory" as 128 by 128 pixel color images in batches of 32:

```python
training_data_generator.flow_from_directory(
"my_data_directory",
class_mode="categorical",
color_mode="rgb,
target_size=(128,128),
batch_size=32)
```

As the training_data_generator loads the data from the directory, it will automatically rescale the pixels by 1/255, and apply the random transformations that we specified earlier.

## Training the model

Now, we are going to put everything together and train our model!

We have do do three additional things:

- Define another ImageDataGenerator and use it to load our validation data.
- Compile our model with an optimizer, metric, and a loss function.
- Train our model using model.fit().

**Validation Data Generator**
We have already defined an ImageDataGenerator called training_data_generator. Like in the second exercise, we use training_data_generator.flow_from_directory() to preprocess and augment our training data.

Now, we need another ImageDataGenerator to load our validation data, which consists of 100 Normal X-rays, and 100 with Pneumonia. Like with our training data, we are going to need to normalize our pixels. However, unlike for our training data, we will not augment the validation data with random shifts.

**Loss, Optimizer, and Metrics**
Because our labels are onehot ([1,0] and [0,1]), we will use keras.losses.CategoricalCrossentropy. We will optimize this loss using the Adam optimizer.

Because our dateset is balanced, accuracy is a meaningful metric. We will also include AUC (area under the ROC curve). An ROC curve gives us the relationship between our true positive rate and our false positive rate. A true positive would be correctly identifying a patient with Pneumonia, while a false positive would be incorrectly identifying a healthy person as having pneumonia. Like with accuracy, we want our AUC to be as close to 1.0 as possible.

**Training the Model**
To train our model, we have to call model.fit() on our training data DirectoryIterator and validation data DirectoryIterator.

To reap the benefits of data augmentation, we will iterate over our training data five times (five epochs).
