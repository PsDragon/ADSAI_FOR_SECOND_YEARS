---
sort: 11
---
# Microsoft Azure Machine Learning I 

Welcome this module on Microsoft Azure Machine Learning! This module is designed to equip you with the skills needed to navigate and effectively utilize Azure ML, a cloud-based tool for training, deploying, and managing ML models. You'll dive into topics ranging from MLOps and Azure ML Workspace management to model training, tuning, and deployment. Plus, we'll tackle advanced topics to elevate your ML expertise. By the end of this module, you'll be able to leverage Azure ML to build and deploy your own ML models in the cloud.

After completing this module you will be able to:

- [ ] Evaluate and apply the levels of MLOps in Azure Machine Learning, using real-world examples to enhance your understanding and implementation of machine learning operations.

- [ ] Utilize an Azure ML Workspace, understanding its functions and benefits in the context of Azure Machine Learning.

- [ ] Execute effective model training and hyperparameter tuning in Azure Machine Learning, understanding the underlying methods and approaches involved.

- [ ] Develop and implement complex machine learning workflows in Azure, including deployment of models and the use of the Azure Machine Learning CLI v2.

## 1. Levels of MLOps and ML OPs Tools üõ†Ô∏è

To streamline and classify the MLOps process, Microsoft has introduced the MLOps Maturity Model. The model outlines five levels of maturity, each of which corresponds to a different stage of implementation and sophistication of MLOps practices within an organization. You have already seen the MLOps Maturity Model in the previous module, but now we take a closer look üîç at the model and how it can be applied in Azure Machine Learning using different Azure tools and services üõ†Ô∏è.

Microsoft's MLOps approach is structured around a maturity model, which helps organizations understand their current maturity level and plan their roadmap for MLOps implementationüó∫Ô∏è. The model comprises five levels:

| Level | Description | 
|---|---|
| Level 0 - No MLOps | At this stage, processes are largely manual and driven by data scientists, with little to no automation in placeüöß. |
| Level 1 - DevOps, no MLOps | Similar to Level 0, but some basic integration tests are addedüö¶. |
| Level 2 - Automated Training | Training processes are tracked, and model artifacts are captured in a repeatable way, but release processes remain manual, and app integration still relies heavily on data scientistsüìä. |
| Level 3 - Automated Model Deployment | Automation extends to model deployment, with a CI/CD pipeline set up for automated releases, but human signoff is still required‚úÖ. |
| Level 4 - Full MLOps | At this level, retraining is automated based on metrics from the application, and A/B testing is added to the CI/CD pipeline. Human signoff may still be needed, but unit and integration tests are in place, and the process is largely automatedüöÄ. |


Moving from level 0 (No MLOps) to level 4 (Full MLOps), the model guides the transition from untracked, manual processes to fully automated, version-controlled workflows with sophisticated metric tracking and testing protocols. The goal is to ensure consistent quality control, streamline the machine learning lifecycle, and enable rapid and reliable deployment of ML models.

To learn more about the MLOps Maturity Model with Azure Machine Learning, please visit [this link](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mlops-maturity-model-with-azure-machine-learning/ba-p/3520625) üîó. 

Focus on the tools and processes that are used at each level. We will introduce the relevant tools and processes in more detail in the following sections.

<div style="text-align: center;">

<img src=./images/azuremlroadmap.png width="1000"/>

</div>

We will be using Azure Machine Learning to manage the lifecycle of machine learning models. This includes creating reproducible machine learning pipelines, registering, packaging, and deploying models, tracking lineage information, sending alerts and notifications for various events in the ML lifecycle, and monitoring ML applications for operational and ML-related issues. 


## 2. Azure Machine Learning [[docs](https://learn.microsoft.com/en-us/azure/machine-learning/?view=azureml-api-2)] 

Azure Machine Learning (Azure ML) üß† is a powerful platform designed to handle every stage of the machine learning lifecycle. It provides robust capabilities that streamline and automate the end-to-end process, from managing your data üìä to deploying your models üöÄ. Each component within Azure ML plays a crucial role in the overall workflow and contributes to a more efficient and productive machine learning process.

<div style="text-align: center;">

<img src=https://learn.microsoft.com/en-us/training/modules/intro-to-azure-ml/media/3-people.gif width="600"/>

</div>

The journey starts with __Data__ üóÇÔ∏è. As the lifeblood of any machine learning project, Azure ML provides tools to manage and version your datasets. This not only keeps your data organized üìö but also ensures robust data governance üõ°Ô∏è.

Next, we move on to __Jobs__ üë∑. These are essentially the tasks or operations that perform the model training. Think of them as the workhorses that carry out the heavy lifting in your machine learning projects.

Then, we have __Components__ üß©. These are the modular building blocks of your machine learning pipelines in Azure. Each step of the process, whether it's data preprocessing, feature extraction, or model training, can be a component. This modular approach enhances flexibility and makes the workflow more manageable.

Up next are __Pipelines__ üè≠. Just as in a manufacturing assembly line, pipelines in Azure ML help orchestrate your machine learning tasks. They allow you to automate workflows, from data preprocessing to model deployment, thereby reducing manual intervention and increasing efficiency.

Dealing with software dependencies can often be a hassle, but not with Azure ML's __Environments__ üå≥. They help track and manage software dependencies, ensuring reproducibility and consistency across different stages of the machine learning lifecycle.

Now, let's talk about __Models__ üèõÔ∏è. Azure ML offers a robust Model Registry for storing, versioning, and managing all your trained machine learning models. Each model is tracked and versioned, making it easier to manage your models' lifecycle.

Finally, we reach __Endpoints__ üéØ. Once your models are ready to make predictions, they're deployed to endpoints. Models are packaged into Docker images before deployment, and they can be deployed as endpoints in the cloud or locallyüåê. Deployment configurations include providing the models, an entry script, a Machine Learning environment, and other necessary assets. Azure ML supports both real-time scoring with online endpoints and large scale scoring with batch endpoints.

It's important to note that Azure Machine Learning provides the capability to track the end-to-end audit trail of all your machine learning assets using metadata. This can be particularly useful for understanding how models arrive at results for specific inputs, meeting regulatory compliance, and maintaining healthy deploymentsüîí. 

Understanding these components and how they interact is key üîë to leveraging the full potential of Azure ML. The platform's comprehensive capabilities provide you with the tools needed to develop high-quality machine learning solutions, all while maintaining efficiency and productivity üí™.

Please complete the following course from Microsoft to learn more about Azure Machine Learning:

- [Intro to Azure ML](https://learn.microsoft.com/en-us/training/modules/intro-to-azure-ml/) üìö

This course will give you a high-level overview of Azure Machine Learning and its capabilities. It will also introduce you to the various components of Azure ML and how they work together to streamline the machine learning lifecycle. :100:

### 2.1 Azure ML Workspace

All the assets mentioned above are stored in an Azure ML Workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. It provides data scientists, ML engineers, and IT professionals with a single view of all the experiments and models in a workspace. The workspace also provides a centralized place to manage the compute targets you use for training and inference.

Complete the following course from Microsoft to learn more about Azure ML Workspace:
- [Explore the Azure ML Workspace](https://learn.microsoft.com/en-us/training/paths/explore-azure-machine-learning-workspace/) üìö

This course will give you a high-level overview of the Azure Machine Learning workspace and how to interact with it. You will also be introduced to the Azure ML SDK, which is a Python package that allows you to interact with Azure ML programmatically. In both parts of this course, you will be first be run through the concepts and then be given a hands-on lab to practice what you've learned. Later in the module we will work through an end-to-end example of using Azure ML to train and deploy a machine learning model with the MNIST project that you have been working on. :1234: 

<div style="text-align: center;">
<img src=images/azuremlworkspace.png width="25%"/><br>
Assets available in an Azure ML Workspace
</div>

### 2.2 Data (üöß Work in progress)

The first step in any machine learning project is to gather and prepare the data. Azure ML provides tools to manage and version your datasets. This not only keeps your data organized üìö but also ensures robust data governance üõ°Ô∏è. The two key concepts to understand are __Datastores__ and __Data Assets__.

| Concept | Description | Usage |
|---|---|---|
| Datastores | Datastores are references to a location where your data resides üåê. They act as a map üó∫Ô∏è pointing to your data treasure chest üì¶. They can point to various Azure services like Blob storage, Data Lake Storage, SQL Database, File Share, etc. They maintain the connection string and other authentication information for you, providing secure and private data access. When you create an Azure workspace, a default datastore (an Azure Blob storage account) is automatically created, but you can also create and use other datastores. | Datastores are used when you need to access raw data from various sources, like Azure Blob storage or Azure Data Lake. You'd typically use them early in a project when you're collecting and preparing your data. |
| Data Assets (Datasets) | Datasets are versioned references to specific subsets of data in your Datastore. Each time a Dataset is modified, a new version is created. This versioning allows you to experiment with different versions of your data üîÑ, and ensures reproducibility of your experiments. You can think of Datasets as the actual treasure in the chest üè∫. | Datasets are used when you have data that is ready for use in experiments, and you want to be able to reuse this data across different experiments and pipelines. Datasets are particularly useful in later stages of a project when you are iterating on different models and need consistency and reproducibility in your data. |
| Data Assets (Data References) | Data References are pointers to the data in your Datastore. They act like bookmarks üîñ in a book, allowing you quick access to a specific location in your Datastore. | Data References are used when you want to work with data directly in its original location (like during data exploration or initial analysis). They are particularly useful when you're working with large amounts of data, or when you want to work with data in its raw form without creating a Dataset. |

Remember, Datastores and Data Assets are complementary. Datastores provide a secure and scalable way to access your data, while Data Assets provide an organized and versioned way to manage and reuse subsets of that data. Using both effectively can help ensure that your machine learning projects are both efficient and reproducible.

#### MNIST Example - Look at how you did it with te MNIST example

Let's take an example of using the popular MNIST dataset in Azure ML.

First, we would establish a Datastore that points to the location of the MNIST data in Azure Blob Storage. This is our map üó∫Ô∏è to the treasure chest üì¶.

```python
from azureml.core import Datastore

blob_datastore = Datastore.register_azure_blob_container(
    workspace=ws, 
    datastore_name='my_blob_store', 
    container_name='mnist-container',
    account_name='my-storage-account',
    account_key='my-storage-account-key'
)
```

Next, we create a Dataset, which is a versioned reference to a specific subset of the data in the Datastore. This is our actual treasure üè∫.

```python
from azureml.core import Dataset

blob_ds = Dataset.Tabular.from_delimited_files(path=(blob_datastore, 'mnist/train.csv'))
blob_ds = blob_ds.register(workspace=ws, 
                           name='mnist_train',
                           description='MNIST training data',
                           create_new_version=True)
```

We now have a Datastore pointing to our raw data, and a Dataset representing a versioned and reusable subset of that data for use in our machine learning experiments!

Please complete the following course from Microsoft and refer to the linked documentation page to learn more about Azure ML Datastores and Data Assets:

- [Working with Data in Azure ML](https://learn.microsoft.com/en-us/training/paths/work-data-azure-machine-learning/):books:
- [Azure Machine Learning Documentation - Tracking Dataset](https://docs.microsoft.com/azure/machine-learning/service/how-to-version-track-datasets).

Remember, understanding the difference and interplay between Datastores and Data Assets is key to efficiently managing data in Azure ML. 

Stay curious and keep exploring! üöÄ

### 2.3 Compute (üöß Work in progress)

Compute targets in Azure Machine Learning are the resources or environments where you run your training scripts or host your service deployments. They can be local or cloud-based and can include your local machine, Docker containers, virtual machines, and more. One of the key benefits of using Azure ML is the ability to dynamically create and manage compute targets that scale with your needs.

Azure Machine Learning supports several types of compute targets:

- Local compute: Your local machine. üíª
- Azure Machine Learning compute instances: Development workstations that data scientists can use to work with data and models. üí°
- Azure Machine Learning compute clusters: Multi-node clusters for scalable training of machine learning models. These clusters can automatically scale up and down according to your configurations and needs, saving costs and optimizing resources. üìà
- Azure Kubernetes Service (AKS): Azure's managed Kubernetes service, ideal for deploying and managing containerized applications more easily. It provides scalable, secure, and robust orchestration services. üê≥
- Azure Machine Learning inference clusters: Deployment targets for real-time inference. ‚ö°
- Attached compute: Other Azure resources like Azure Databricks, Azure Data Lake Analytics, or virtual machines. ‚òÅ

To manage your compute targets, you can list all the available compute targets in your workspace and then select the one that suits your needs. Here is an example of how you can list your compute targets using the Azure ML Python SDK:

```python
from azureml.core import Workspace

ws = Workspace.from_config()

# List all compute targets in the workspace
for compute_name in ws.compute_targets:
    compute = ws.compute_targets[compute_name]
    print(compute.name, ":", compute.type)
```

And this is an example of how you can select a specific compute target:

```python
# Get a specific compute target
compute_target = ws.compute_targets['my-compute-target']
```

In many scenarios, using a compute cluster is ideal because it can automatically scale according to the workload. This feature is particularly useful for running Designer pipeline jobs, Automated Machine Learning jobs, or scripts as jobs, where multiple models can be trained in parallel. 

Complete the following course from Microsoft to learn more about Azure ML Compute:

# ADD SOMETHING ABOUT CREATING RESOURCES IS OPTIONAL 

- [Working with Compute in Azure ML](https://learn.microsoft.com/en-us/training/paths/work-compute-azure-machine-learning/) :books:

### 2.4 Environments (üöß Work in progress)

Azure Machine Learning environments are an encapsulation of the training script, runtime, and associated packages needed for model training and scoring. Each environment consists of a Docker container and a Python environment. They play a vital role in ensuring the reproducibility and consistency of machine learning workflows across different stages and on various compute targets.

With Azure ML environments, you can:

- Specify Python packages and versions required for your training and deployment scripts.
- Manage environments by creating new ones, getting existing ones, and listing all environments in your workspace.
- Version environments to keep track of the package changes and to ensure reproducibility of your experiments.
- Reuse your environments across different experiments and deployments.

Here is an example of how to create a new environment with specific Python packages:

# MAKE THESE EXAMPLES BETTER
LOOK HOW YOU DID IT IN THE MNIST EXAMPLE

```python
from azureml.core import Environment

myenv = Environment(name="myenv")
myenv.python.conda_dependencies.add_pip_package("scikit-learn==0.24.2")
```

Complete the following course from Microsoft and refer to the linked documentation page to learn more about Azure ML Environments:

- [Working with Environments in Azure ML](https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/) :books:
- [Azure Machine Learning Documentation - Environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments).

Remember, using Azure ML Environments is key to managing software dependencies efficiently and ensuring the consistency of your machine learning workflows across different compute targets. Stay curious and keep exploring! üöÄ







### 2.3 Compute

Explain what a compute target is and how to list and select compute targets.

Make the lesson on creating compute optional.

https://learn.microsoft.com/en-us/training/paths/work-compute-azure-machine-learning/

Use a compute cluster
There are three main scenarios in which you'll want to use a compute cluster:

Running a pipeline job you built in the Designer.
Running an Automated Machine Learning job.
Running a script as a job.
In each of these scenarios, a compute cluster is ideal as a compute cluster will automatically scale up when a job is submitted, and automatically shut down when a job is completed.

A compute cluster will also allow you to train multiple models in parallel, which is a common practice when using Automated Machine Learning.

You can run a Designer pipeline job and an Automated Machine Learning job through the Azure Machine Learning studio. When you submit the job through the studio, you can set the compute target to the compute cluster you created.

When you prefer a code-first approach, you can set the compute target to your compute cluster by using the Python SDK.

For example, when you run a script as a command job, you can set the compute target to your compute cluster with the following code:

```python
from azure.ai.ml import command

# configure job
job = command(
    code="./src",
    command="python diabetes-training.py",
    environment="AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest",
    compute="cpu-cluster",
    display_name="train-with-cluster",
    experiment_name="diabetes-training"
    )

# submit job
returned_job = ml_client.create_or_update(job)
aml_url = returned_job.studio_url
print("Monitor your job at", aml_url)
```

After submitting a job that uses a compute cluster, the compute cluster will scale out to one or more nodes. Resizing will take a few minutes, and your job will start running once the necessary nodes are provisioned. When a job's status is preparing, the compute cluster is being prepared. When the status is running, the compute cluster is ready, and the job is running.


### Environments

https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/







### 2.4 Environments

Azure Machine Learning environments are vital in ensuring reproducibility and consistency of machine learning workflows. They allow you to encapsulate your training script, runtime, and associated packages, including your Docker container, needed for model training and scoring.

Here's an example of how you can use your own Docker container in an Azure ML environment:

```python
from azureml.core import Environment

myenv = Environment(name="myenv")

myenv.docker.enabled = True
myenv.docker.base_image = None
myenv.docker.base_dockerfile = """
FROM ubuntu:18.04
RUN apt-get update && \
    apt-get install -y python3-pip && \
    pip3 install azureml-defaults
"""
```

In this script, we create a new environment and set the `base_dockerfile` property to define the Dockerfile that will be used to create the Docker image for our environment. This way, we can use a custom Docker container. 

Remember, using Azure ML environments is key to managing software dependencies efficiently, ensuring the consistency of your machine learning workflows, and providing a high level of flexibility in your workflows. üöÄ

Don't forget to check out these resources to further expand your knowledge:

- [Working with Compute in Azure ML](https://learn.microsoft.com/en-us/training/paths/work-compute-azure-machine-learning/) :books:
- [Working with Environments in Azure ML](https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/) :books:
- [Azure Machine Learning Documentation - Environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments).

Stay curious and keep exploring! üöÄüí°üåê