---
sort: 12
---

# Introduction to Containerization for Data Science and AI ğŸ“šğŸ§ªğŸ’» (ğŸš§ Work in progress)

This module forms a part of the larger MLOps curriculum designed for data science and AI students. It provides a fundamental understanding of containerization ğŸ“¦, an essential concept in the field of MLOps (Machine Learning Operations). This course will explore the principles of containerization and how it enables more efficient, scalable, and reliable systems ğŸ”’, which are crucial for successful machine learning models in production. The focus will be on understanding containerization and deploying a Python-based Machine Learning application using Docker.

By the end of this one-day course, students will be able to:

- [ ] Understand the core concepts of containerization and its advantages.
- [ ] Use Docker to create and manage containers.
- [ ] Containerize and deploy a Python-based Machine Learning application using Docker.

---

## 1. Understanding Virtualization ğŸ’»

Before we delve into the world of containerization, it's important to understand the concept of virtualization, as both technologies aim to provide isolated and reproducible environments for applications.

Virtualization is a technology that allows you to create multiple simulated environments or dedicated resources from a single, physical hardware system. At its core, virtualization is about abstracting the hardware to allow a single machine to run multiple operating systems simultaneously.

### Types of Virtualization

1. **Hardware or Platform Virtualization**: This is the most common type of virtualization. It involves installing a hypervisor on top of the host's operating system. The hypervisor directly interacts with the physical server's CPU, memory, and other resources. It serves as a platform for virtual machines (VMs), each with its own operating system and installed applications.

2. **Operating System Virtualization or Containerization**: This form involves virtualizing the operating system so that you can run multiple instances (containers) on a single host. Each container shares the host's operating system but runs in isolation from the others. Containerization offers a lightweight alternative to full machine virtualization.

### Virtual Machines vs Containers ğŸ ğŸ¢

Understanding the difference between virtual machines and containers is key to understanding why containers have gained so much popularity.

- **Virtual Machines** ğŸ : Each VM includes a full copy of an operating system, the application, necessary binaries, and libraries - taking up tens of GBs. VMs can also be slow to boot. They are also tied to the infrastructure they run on, making them less portable. Think of VMs as houses. Each house (VM) is fully self-contained with its own infrastructure such as plumbing and electrical (OS and individual system resources). Just as houses don't share these resources with each other, each VM runs its own operating system independently, requiring a full stack from the OS up to the application code to run. This can lead to a lot of redundancy and wasted resources, much like having a whole house just for one person.

- **Containers** ğŸ¢: Containers include the application and all of its dependencies but share the kernel with other containers. They run as an isolated process in userspace on the host operating system. They are not tied to any specific infrastructure â€“ they run on any computer, on any infrastructure, and in any cloud. Containers are more like apartments in an apartment building. The building (the host system) itself provides the infrastructure (OS, network, storage), and each apartment (container) includes just the rooms (application and its dependencies) required for the person (the specific service or application the container is running). Since all apartments in the building share the same infrastructure, you can fit many more apartments onto the same amount of land compared to individual houses. Each apartment is self-contained and fully functional, but much smaller than a house. This makes them lightweight and portable.

<div style="text-align:center">
<img src="images/containersvsvms.png" width="80%">
</div>

Containers offer several advantages over virtual machines:

- **Efficiency**: Containers are incredibly lightweight because they leverage and share the host kernel.
- **Speed**: Containers start almost instantly. They are created, started, and stopped in a matter of seconds.
- **Portability**: A containerized application can run anywhere without worrying about the underlying infrastructure.
- **Scalability**: Containers can be scaled up and down quickly to match the demands of the application.

---

## 2. Understanding Containerization ğŸ“¦

## What is a container? ğŸ“¦

A container is a lightweight, standalone, executable software package that includes everything needed to run a piece of software, including the code, runtime, system tools, libraries, and settings. Containers help to isolate applications from the underlying system, ensuring that they run consistently across different computing environments.

<div style="text-align:center">
<img src="images/containers.png" width="40%">
</div>

## Why use containers? ğŸ¤”

Containers offer several benefits for data science and AI applications:

1. **Consistency**: Containers ensure that applications run consistently across different environments, reducing the "it works on my machine" problem.
2. **Isolation**: Containers help isolate applications from the underlying system, providing better security and reducing potential conflicts between dependencies.
3. **Portability**: Containers make it easy to share and deploy applications across various platforms, simplifying the deployment process.
4. **Scalability**: Containers can be easily scaled up or down, making them a perfect fit for resource-intensive tasks like machine learning.
5. **Easier collaboration**: Containers help streamline collaboration between team members, as everyone can work with the same environment and dependencies.

## Containerization for ML ğŸ§ª

Containerization is particularly beneficial for machine learning applications, as it addresses several challenges faced by data scientists and AI practitioners:

1. **Dependency management**: Containerization simplifies the management of complex dependencies, ensuring that machine learning models work as expected across different environments.
2. **Reproducibility**: Containers help maintain reproducibility in ML workflows by capturing the entire environment, including data, code, and libraries.
3. **Version control**: Containers allow for easy versioning of models and their environments, making it simple to roll back to a previous version if needed.
4. **Deployment**: Containers make it easy to deploy machine learning models to production environments, streamlining the process and reducing potential errors.

<div style="text-align:center">
<img src="https://ml-ops.org/img/infra-cloud.jpg" width="70%">
</div>

---

## 3. Docker ğŸ³

[Docker](https://www.docker.com/) is a popular containerization platform that allows you to create, deploy, and manage containers. It is an open-source project that provides a simple and lightweight way to containerize applications. Docker is widely used in the industry and is supported by all major cloud providers, making it an excellent choice for containerizing machine learning applications.

<img src="images/docker1.png" width="100%">

- Please complete the following course on DataCamp to learn more about Docker: [Introduction to Docker](https://app.datacamp.com/learn/courses/introduction-to-docker) ğŸ“š

        âš ï¸ Note: you only need to do the first 3 chapters.

- You can access the Docker documentation [here](https://docs.docker.com/get-started/overview/):link:

### Docker Components ğŸ§©

To understand Docker better, let's take a look at its main components:

1. **Docker Engine** ğŸš‚: Docker Engine is the heart of Docker. It's a lightweight runtime that builds and runs your Docker containers. Docker Engine is a client-server type of application that consists of a server which is a type of long-running program called a daemon process, a REST API that specifies interfaces that programs can use to talk to the daemon and instruct it what to do, and a command-line interface (CLI) client.
 
2. **Docker Images** ğŸ–¼ï¸: Docker images are read-only templates that your Docker containers are based on. You can think of them as a blueprint for Docker containers. They contain everything needed to run an application - the code or binary, runtimes, dependencies, and any other filesystem objects required.

3. **Docker Containers** ğŸ“¦: Docker containers are runtime instances of Docker images. They encapsulate the application and its dependencies, making it portable and consistent across different environments. Each container runs as an isolated process in the user space of the host operating system.

4. **Dockerfile** ğŸ“„: A Dockerfile is a text file that contains a list of commands that the Docker daemon calls while creating an image. It's essentially a blueprint for building Docker images and automating the process.

5. **Docker Registry** ğŸ—„ï¸: A Docker registry is a repository for Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can also set up your own private registry.

6. **Docker Hub** ğŸŒ: Docker Hub is a cloud-based registry service that allows you to link code repositories, build details, and more. It provides a centralized resource for container image discovery, distribution, change management, related third-party services, and workflow automation throughout the development pipeline.

### Docker Workflow ğŸ”„

Here's a basic Docker workflow:

1. **Create a Dockerfile**: This file will define what goes on in the environment inside your container.

2. **Build an Image**: Using Docker build, you create a Docker image based on the Dockerfile.

3. **Run the Image**: From this image, Docker creates a container where your application will run.

4. **Push to a Registry**: If you're planning to run your application across different environments, you would want to push your image to a registry like Docker Hub.

5. **Pull and Run the Image from the Registry**: You then pull the image from the registry and tell Docker to run this image on any machine that supports Docker, ensuring consistency across different environments.

<div style="text-align:center">
<img src="https://k21academy.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-26-11-01-09.png" width="70%">
</div>

By understanding these components and the basic workflow, you can begin to see the potential of Docker. But, of course, Docker's true power comes when you start working with complex applications that require linking multiple containers, scaling up and down to manage loads, and deploying applications on remote hosts, for which you would use orchestration tools like Docker Swarm or Kubernetes.

Docker provides the flexibility and performance capabilities to encapsulate and containerize your applications and microservices, making it an essential tool in the MLOps and DevOps toolchain.

### Docker Cheatsheet ğŸ“

Here is a list of commonly used Docker commands and some Dockerfile instructions that you might find useful:

#### Docker Commands

- `docker ps`: List running containers.
- `docker ps -a`: List all containers (both running and stopped).
- `docker run -it <image>`: Run an image in interactive mode.
- `docker run -d -p <host-port>:<container-port> <image>`: Run an image in detached mode (in the background) and map ports.
- `docker stop <container>`: Stop a running container.
- `docker rm <container>`: Remove a container.
- `docker images`: List all images.
- `docker rmi <image>`: Remove an image.
- `docker pull <image>`: Pull an image from a registry.
- `docker push <image>`: Push an image to a registry.
- `docker build -t <tag> .`: Build an image from a Dockerfile (the '.' indicates that the Dockerfile is in the current directory).
- `docker exec -it <container> <command>`: Execute a command in a running container.
- `docker logs <container>`: View the logs of a container.

#### Dockerfile Instructions

- `FROM`: Set the base image for subsequent instructions. In every valid Dockerfile, this will be the first instruction.
- `RUN`: Execute any commands in a new layer on top of the current image and commit the results.
- `CMD`: Provide defaults for an executing container. This can include an executable or they can omit the executable, in which case you must specify an ENTRYPOINT instruction.
- `LABEL`: Add metadata to an image.
- `EXPOSE`: Inform Docker that the container listens on the specified network ports at runtime.
- `ENV`: Set the environment variable <key> to the value <value>.
- `ADD`: Copy new files, directories or remote file URLs from <src> and add them to the filesystem of the image at the path <dest>.
- `COPY`: Similar to ADD, but without the extra features like copying from URLs or extracting TAR files.
- `ENTRYPOINT`: Allows you to configure a container that will run as an executable.
- `VOLUME`: Creates a mount point with the specified name and marks it as holding externally mounted volumes from the native host or other containers.
- `USER`: Sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile.
- `WORKDIR`: Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.

Here is an example of a Dockerfile:

```Dockerfile
# Use an official Python runtime as a parent image
FROM python:3.7-slim

# Set the working directory in the container to /app
WORKDIR /app

# Add metadata to the image
LABEL maintainer="yourname@example.com"

# Copy the current directory contents into the container at /app
COPY . /app

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Make port 80 available to the world outside this container
EXPOSE 80

# Run app.py when the container launches
CMD ["python", "app.py"]
```

This Dockerfile uses a Python 3.7 image, sets the working directory to `/app`, copies the contents of the current directory into the container, installs necessary packages, exposes port 80, and runs `app.py` on launch.

Remember, the best way to get comfortable with Docker commands and Dockerfiles is through practice. The more you work with Docker, the more these commands will become second nature. In the next section, we will walk through an example of how to containerize a machine learning application using Docker.

---


## 4. Example: MNIST App in a container ğŸ–‹ï¸

In this example, we will containerize a simple Python-based machine learning application that recognizes handwritten digits using the MNIST dataset. You may recognize this application from the [Application Programming Interfaces (APIs)]() course page.

1. **Create a Python ML application**: Develop a Python application that trains a machine learning model using the MNIST dataset and saves the trained model.

2. **Write a Dockerfile**: Create a Dockerfile that specifies the base image, installs the necessary dependencies, and sets up the environment for your application.

3. **Build the Docker image**: Use Docker to build the image for your application using the Dockerfile.

4. **Run the Docker container**: Deploy your application by running the Docker container.

5. **Test the application**: Test the application to ensure that it works as expected within the container.

By following these steps, you will successfully containerize and deploy a Python-based machine learning application using Docker. Let's get started! ğŸ¢

### 4.1. Create a Python ML application ğŸ

The first step is to create a Python application that trains a machine learning model using the MNIST dataset and saves the trained model. You can find the code for this application in the `mnist_app` folder.

### 4.2. Write a Dockerfile ğŸ“

The next step is to write a Dockerfile that specifies the base image, installs the necessary dependencies, and sets up the environment for your application.

Here is the Dockerfile for this application:

```Dockerfile
# Use an official Python runtime as a parent image

```

### 4.3. Build the Docker image ğŸ—ï¸

### 4.4. Run the Docker container ğŸƒ

### 4.5. Test the application ğŸ§ª

### 4.6. Push the image to Docker Hub ğŸ“¤

## 5. Conclusion ğŸ‰

## 6. Additional Resources ğŸ“š

- [Docker Documentation](https://docs.docker.com/)