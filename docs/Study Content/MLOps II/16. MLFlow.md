---
sort: 15
---

# Creating Reproducible ML Experiments with MLFlow and Azure ML üöÄ

In the dynamic field of data science, it is crucial to have an organized and structured way to manage your machine learning (ML) projects. That's where MLFlow comes in! MLFlow is an open-source platform designed to manage the entire machine learning lifecycle, including experimentation, reproducibility, and deployment. When combined with Azure Machine Learning (AML), a cloud-based service for building, training, and deploying machine learning models, you gain access to a powerful, scalable platform for your ML projects.

After completing this module, you will be able to:

- üéØ Understand the fundamental concepts of MLFlow and Azure Machine Learning.
- üéØ Use MLFlow to manage ML experiments, including tracking, packaging, and reproducing runs.
- üéØ Integrate MLFlow with Azure ML to leverage cloud-based resources for ML project lifecycle management.
- üéØ Design and implement reproducible ML experiments using MLFlow and Azure ML.

## Why use MLFlow with Azure ML? ü§î

MLFlow and Azure ML complement each other wonderfully. While MLFlow provides a robust framework for managing your ML lifecycle, Azure ML offers scalable cloud-based resources to support training, testing, and deployment of your models. This combination allows you to have a flexible and scalable ML environment, perfect for individual projects and collaborative efforts.

## MLFlow Concepts üìò

MLFlow comprises four main components:

- **MLFlow Tracking:** This is an API and UI for logging parameters, code versions, metrics, and output files when running your ML code and for later visualizing the results. You can use it in any environment (standalone scripts, notebooks, etc.) to log results to local files or a server.

- **MLFlow Projects:** This is a standard format for packaging reusable data science code. Each project is simply a directory with code or a git repository, and uses a descriptor file to specify its dependencies and how to run the code.

- **MLFlow Models:** This is a standard format for packaging machine learning models that allows you to easily share or deploy models across a variety of ML libraries, or even as a REST API in the cloud.

- **MLFlow Registry:** This is a centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an MLflow Model.

When integrated with Azure ML, you can harness the cloud's scalability and manage MLFlow's components more efficiently. Azure ML's MLOps (DevOps for machine learning) streamline the build, training, deployment, and management of machine learning models.

This video provides a great overview of MLFlow and using it with Azure ML: üìΩÔ∏è

<div style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/2DLG1yo8JxM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

For more details on MLFlow  and how to use it with Azure ML, please visit the following links: üìö

- [MLFlow in AzureML](https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/) - Microsoft Learn Course Module

- [Azure ML Python SDK v2 and MLFlow](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow?view=azureml-api-2) - Microsoft Azure Docs

- [MLFlow Quickstart](https://mlflow.org/docs/latest/quickstart.html) - MLFlow Quickstart Docs

- [Data Camp Tutorial](https://www.datacamp.com/tutorial/mlflow-streamline-machine-learning-workflow) - Data Camp Tutorial

## MLFlow Cheat Sheet üìÑ

- **Start an MLflow run:** This is how you start tracking an experiment.
    ```python
    import mlflow
    mlflow.start_run()
    ```
- **Log parameters, metrics, and a model:** During a run, you can log key-value pairs of parameters and metrics. You can also save a trained model:
    ```python
    mlflow.log_param("param1", 1)
    mlflow.log_metric("metric1", 1.1)
    ```
- **Log an artifact (output file):** You can save any file as an artifact. For example, you can log a plot as an image file:
    ```python
    import matplotlib.pyplot as plt
    fig = plt.figure()
    plt.plot([0, 1], [0, 1])
    plt.xlabel("x")
    plt.ylabel("y")
    plt.title("title")
    mlflow.log_figure(fig, "fig1.png")
    ```
- **Use autolog:** With `autolog()`, MLflow automatically logs all relevent information from supported machine learning libraries. :
    ```python
    mlflow.autolog()
    ```
   This will automatically log metrics, parameters, and a model from the ML library you are using. It's a very powerful tool to reduce manual logging and make the code cleaner. Any details that aren't logged automatically can be logged manually.

   When you call `autolog()`, MLflow tracks the following for subsequent fitting function invocations:

    - Hyperparameters: Includes any arguments passed to the fit function.
    - Output: Log model-specific metrics and save the model in an MLflow Model format that can be used for later inference.
    - Code version: Tracks the git commit hash (if applicable).
    - Environment: Captures information about the conda environment.
    - Extras: Logs additional metadata as tags.

    Here's an example of `autolog()` usage with scikit-learn:

    ```python
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.datasets import make_regression
    import mlflow.sklearn

    # Autolog
    mlflow.autolog()

    # Prepare training data
    X, y = make_regression()
    X_train, X_test, y_train, y_test = train_test_split(X, y)

    # Train the model
    rf = RandomForestRegressor()
    rf.fit(X_train, y_train)

    # The metrics, parameters, model artifact, and other details are automatically logged
    ```
   
- **End a run:** To stop tracking the experiment, simply end the run:
    ```python
    mlflow.end_run()
    ```
- **Using MLflow with Azure ML:** To utilize Azure ML's resources with MLflow, you'll first need to connect to your Azure ML workspace and then start an experiment:
    ```python
    from azureml.core import Workspace
    import mlflow

    workspace = Workspace.from_config()
    mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())
    mlflow.start_run(experiment_id='my-experiment')
    ```

## Additional Resources üîñ

Explore these examples and code snippets to solidify your understanding and practice MLFlow and Azure ML:

- [Simple Keras Example](https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py)
- [PyTorch Examples](https://github.com/mlflow/mlflow/tree/master/examples/pytorch) - These are quite detailed and a bit complex
- [More Tensorflow Examples](https://github.com/mlflow/mlflow/tree/master/examples/tensorflow) - These are quite detailed and a bit complex

## Additional Resources üîñ

Explore these examples and code snippets to solidify your understanding and practice MLFlow and Azure ML:

- [Simple Keras Example](https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py)
- [PyTorch Examples](https://github.com/mlflow/mlflow/tree/master/examples/pytorch) - These are quite detailed and a bit complex
- [More Tensorflow Examples](https://github.com/mlflow/mlflow/tree/master/examples/tensorflow) - These are quite detailed and a bit complex


## Worked Example - MNIST with Keras (Work in Progress üöß)


## Worked Example - MNIST with PyTorch (Work in Progress üöß)