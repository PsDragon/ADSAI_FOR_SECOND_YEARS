{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formed-utilization",
   "metadata": {},
   "source": [
    "Next week, you will start developing NLP models to classify positive and negative tweets. You will use the NLTK twitter samples dataset.\n",
    "\n",
    "**Twitter Samples dataset documentation**\n",
    "\n",
    "These samples of Tweets (or 'status updates') were collected from the\n",
    "Twitter Streaming and REST APIs. Each file consists of\n",
    "line-separated JSON-formatted tweets, i.e. one Tweet per line. For a\n",
    "detailed description of the JSON fields in a Tweet, see\n",
    "https://dev.twitter.com/overview/api/tweets.\n",
    "\n",
    "Any use of this data is subject to the Twitter Developer Agreement and\n",
    "Developer Policy:\n",
    "https://dev.twitter.com/overview/terms/agreement-and-policy.\n",
    "\n",
    "These were collected in July 2015 by searching against the following strings:\n",
    "\n",
    "positive_tweets.json\n",
    "\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    }\n",
    "\n",
    "negative_tweets.json\n",
    "\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-crest",
   "metadata": {},
   "source": [
    "Before developing sentiment analysis models on this dataset, you need to be able to process tweets. This is what you will learn in this datalab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-norman",
   "metadata": {},
   "source": [
    "**Task 1: Start with a simple EDA on the dataset.**\n",
    "\n",
    "- What is the data type of `all_positive_tweets` and `all_negative_tweets`\n",
    "- What is the data type of a tweet entry\n",
    "- How many tweets are there in each class\n",
    "- Print a single tweet from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Positive class:')\n",
    "print(all_positive_tweets[random.randint(0,5000)]+'\\n')\n",
    "\n",
    "print('Negative class:')\n",
    "print(all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = ('My beautiful sunflowers on a sunny Friday morning off :)'\n",
    "                 ' #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i')\n",
    "print(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-conviction",
   "metadata": {},
   "source": [
    "Next, you will create a function called `tweet_processor()`. Task by task, you will add more functionality to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a string containing the processed tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_tweet = tweet # no processing so far\n",
    "    \n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-vegetable",
   "metadata": {},
   "source": [
    "**Task 2: Remove hyperlinks from a tweet**\n",
    "\n",
    "Using `re.sub()`, write a regular expression to remove hyperlinks. Add this to the function `tweet_processor()`.\n",
    "\n",
    "Example tweet:\n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "`'My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… '`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a string containing the processed tweet\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "    \n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_processor(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-frame",
   "metadata": {},
   "source": [
    "**Task 3: Remove hashtags from the tweets**\n",
    "\n",
    "Add a `re.sub()` and a suitable pattern to the `tweet_processor()` function to remove the `#` sign from the word.\n",
    "\n",
    "Example tweet:\n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "`'My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… '`\n",
    "\n",
    "Notice that `tweet_processor()` now removes both hyperlinks and hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a string containing the processed tweet\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_processor(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-wildlife",
   "metadata": {},
   "source": [
    "**Task 4: Tokenize a tweet**\n",
    "\n",
    "Use `TweetTokenizer` from `nltk` to tokenize tweets. Add this to the `tweet_processor()` function.\n",
    "\n",
    "Example tweet:\n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "`['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '…']`\n",
    "\n",
    "Notice that the output is not a string anymore. It is a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-counter",
   "metadata": {},
   "source": [
    "Decide which arguments to provide to the following parameters:\n",
    "\n",
    "- **preserve_case** (bool) – Flag indicating whether to preserve the casing (capitalisation) of text used in the tokenize method. Defaults to True. \n",
    "\n",
    "- **reduce_len** (bool) – Flag indicating whether to replace repeated character sequences of length 3 or greater with sequences of length 3. Defaults to False.\n",
    "\n",
    "- **strip_handles** (bool) – Flag indicating whether to remove Twitter handles of text used in the tokenize method. Defaults to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_processor(example_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-minutes",
   "metadata": {},
   "source": [
    " **Task 5: Remove stopwords and punctuation.**\n",
    " \n",
    " Go through every word in your tokens list, remove stopwords and punctuation. Add this to the function `tweet_processor()`.\n",
    " \n",
    " Example tweet:\n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "`['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '…']`\n",
    "\n",
    "Take a look at which tokens are removed and try to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_english = stopwords.words('english') \n",
    "print(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "    - Removes stopwords and punctuation\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_processor(example_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-feedback",
   "metadata": {},
   "source": [
    "**Task 6: Stem the tokens**\n",
    "\n",
    "Use PorterStterm from NLTK to convert tokens to stems.\n",
    "https://en.wikipedia.org/wiki/Stemming\n",
    "\n",
    "Add this functionality to tweet_processor() function.\n",
    "\n",
    "Example tweet:\n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "`['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "    - Removes stopwords and punctuation\n",
    "    - Stem tokens\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_processor(example_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-consequence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
