{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corrected-islam",
   "metadata": {},
   "source": [
    "## 1. Tweet preprocessing (previous datalab)\n",
    "\n",
    "Before starting the DataLab, preprocess the tweets like you did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-sheet",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "    - Removes stopwords and punctuation\n",
    "    - Stem tokens\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = all_positive_tweets[2277]\n",
    "tweet_processed = tweet_processor(tweet)\n",
    "\n",
    "print(tweet)\n",
    "print(tweet_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training 20% testing\n",
    "positive_tweets_tr = all_positive_tweets[:4000]\n",
    "positive_tweets_te = all_positive_tweets[4000:]\n",
    "\n",
    "negative_tweets_tr = all_negative_tweets[:4000]\n",
    "negative_tweets_te = all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-genius",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tweet_processor_list(tweet_list):\n",
    "    # YOUR CODE HERE #\n",
    "    return processed_tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets_tr = tweet_processor_list(positive_tweets_tr)\n",
    "positive_tweets_te = tweet_processor_list(positive_tweets_te)\n",
    "\n",
    "negative_tweets_tr = tweet_processor_list(negative_tweets_tr)\n",
    "negative_tweets_te = tweet_processor_list(negative_tweets_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-abortion",
   "metadata": {},
   "source": [
    "You already did the steps until here in the previous DataLab. Let's do a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(positive_tweets_tr) == 4000\n",
    "assert len(negative_tweets_tr) == 4000\n",
    "\n",
    "assert len(positive_tweets_te) == 1000\n",
    "assert len(negative_tweets_te) == 1000\n",
    "\n",
    "assert type(positive_tweets_tr) is list\n",
    "assert type(positive_tweets_tr[0]) is list\n",
    "assert type(positive_tweets_tr[0][0]) is str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-bahrain",
   "metadata": {},
   "source": [
    "## 2. Converting tweets to numbers (previous datalab)\n",
    "\n",
    "Repeat your code from the last datalab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets = positive_tweets_tr + negative_tweets_tr\n",
    "test_tweets = positive_tweets_te + negative_tweets_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-wonder",
   "metadata": {},
   "source": [
    "While we are creating our dataset, we can also create our labels. We know that first half of `training_tweets` and `test_tweets` are positive (label = 1) and second half is negative (label = 0). Therefore creating the labels is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.append(np.ones(len(positive_tweets_tr)),\n",
    "                    np.zeros(len(negative_tweets_tr)))\n",
    "\n",
    "y_test = np.append(np.ones(len(positive_tweets_te)),\n",
    "                   np.zeros(len(negative_tweets_te)))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-fusion",
   "metadata": {},
   "source": [
    "Remember that we already preprocessed and tokenized our tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-sudan",
   "metadata": {},
   "source": [
    "But Keras `Tokenizer()` expects a list of strings. So let's combine tokens into strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_str = []\n",
    "for tw in training_tweets:\n",
    "    training_tweets_str.append(' '.join(tw))\n",
    "    \n",
    "test_tweets_str = []\n",
    "for tw in test_tweets:\n",
    "    test_tweets_str.append(' '.join(tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-charger",
   "metadata": {},
   "source": [
    "**Task 2.1**\n",
    "\n",
    "Use tokenizer on `training_tweets_str`. Notice that tokenizer processes text with the `filters` parameter. Set it to `filters=''` to prevent processing because we already processed our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-advance",
   "metadata": {},
   "source": [
    "**Task 2.2**\n",
    "\n",
    "Calculate the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-scientist",
   "metadata": {},
   "source": [
    "**Task 2.3**\n",
    "\n",
    "Find the numbers that represent the words `'boy'`, `'girl'`, `'man'` and `'woman'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-picture",
   "metadata": {},
   "source": [
    "**Task 2.4**\n",
    "\n",
    "Convert training and test tweets to sequences and use padding.\n",
    "\n",
    "Example tweet:\n",
    "\n",
    "`'followfriday top engag member commun week :)'`\n",
    "\n",
    "Corresponding sequence:\n",
    "\n",
    "`[347, 221, 937, 400, 286, 52, 3]`\n",
    "\n",
    "Padded sequence:\n",
    "\n",
    "`array([347, 221, 937, 400, 286,  52,   3,   0,   0,   0,   0,   0,   0,\n",
    "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "         0,   0,   0,   0], dtype=int32)`\n",
    "\n",
    "\n",
    "For padding arguments use `padding='post'` and `maxlen=30`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert training_padded.shape == (8000, 30)\n",
    "assert test_padded.shape == (2000, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-crystal",
   "metadata": {},
   "source": [
    "## 3. Combine embedding layer with RNNs (this datalab)\n",
    "\n",
    "Create a model with the following layers:\n",
    "- Embedding layer\n",
    "- Recurrent layer\n",
    "- Dense layer\n",
    "\n",
    "This is the minimum architecture. You can modify it to increase the number of layers or add new layers such as Dropout.\n",
    "\n",
    "Keras provides a few recurrent layers:\n",
    "\n",
    "- LSTM layer\n",
    "- GRU layer\n",
    "- SimpleRNN layer\n",
    "- TimeDistributed layer\n",
    "- Bidirectional layer\n",
    "- ConvLSTM1D layer\n",
    "- ConvLSTM2D layer\n",
    "- ConvLSTM3D layer\n",
    "- Base RNN layer\n",
    "\n",
    "https://keras.io/api/layers/recurrent_layers/\n",
    "\n",
    "For your recurrent layer try LSTM, GRU and SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_padded\n",
    "X_test = test_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import # YOUR CODE HERE #\n",
    "\n",
    "model = Sequential()\n",
    "# YOUR CODE HERE #\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-overall",
   "metadata": {},
   "source": [
    "**Task 3.2**\n",
    "\n",
    "Compile the model by selecting a proper loss, optimizer and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-lesbian",
   "metadata": {},
   "source": [
    "**Task 3.3**\n",
    "\n",
    "Train the model with `X_train` and `y_train`. Use `X_test` and `y_test` as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-metro",
   "metadata": {},
   "source": [
    "**Task 3.4**\n",
    "\n",
    "Predict the class of a test tweet.\n",
    "\n",
    "Example tweet:\n",
    "`\"back thnx god i'm happi :)\"`\n",
    "\n",
    "Model prediction:\n",
    "`array([[0.99999976]], dtype=float32)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets_str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-credit",
   "metadata": {},
   "source": [
    "## 4. Bidirectional LSTM (this datalab)\n",
    "\n",
    "Try bidirectional LSTMs.\n",
    "\n",
    "https://keras.io/examples/nlp/bidirectional_lstm_imdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pottery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
