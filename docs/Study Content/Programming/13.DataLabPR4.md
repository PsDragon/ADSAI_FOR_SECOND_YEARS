---
sort: 13
---
# Data Lab: Creative Brief

If you had succesfully completed the workshops this week, you should
now have:

- [x] your Github contains the ```banijay_EDA``` folder with the 
    - [x] ```banijay_data_content.ipynb``` notebook which reads in the raw content data, processes it, and saves the processed data.
    - [x] ```banijay_data_ratings.ipynb``` notebook which reads in the raw ratings data.
    - [x] A ```data``` folder containing the raw and processed data files.
    - [x] your Twitter developer account is activated and you have your API keys and tokens.

In **today's data lab**, we continue with the use-cases and the key addition for today is <mark>the use of social media data.</mark> 

Before we start, please make sure you have read the sections on [The final report](https://adsai.buas.nl/Study%20Content/Programming/11.DataLabPR3.html#the-final-report) and [Plagiarism](https://adsai.buas.nl/Study%20Content/Programming/11.DataLabPR3.html#plagiarism) you can find in the bottom of this page.

**Let's get started: Keep the coffee flowing and the music playing!** 

:thumbsup: :headphones:  :coffee:

## Use-case 1: Linking Content Data to Ratings Data 

 As you may have noticed, the content data and ratings data are stored in different files. In order to perform any analysis, you will need to link the two datasets. 
 
 However, merging datasets often requires a common key. 
 For example, if we have one data frame containing ```student_id``` and ```student_name``` and another data frame containing ```student_id``` and ```student_grade```, we can merge the two data frames on the ```student_id``` column and create a dataframe containing the three columns which we can use for further analysis.

 Ideally, we would like to merge the content data and ratings data on the ```content_id``` column. However, the content data contains a ```content_id``` column, while the ratings data does not. Therefore, we need to figure out a way to still be able to merge the two datasets.

To solve this use-case, you will need to:

- [ ] create a lookup table that allows you link the content and the ratings data. In simpler terms, every ratings in the ratings data should be linked to a show, and specifically a fragment in the content data.
- [ ] use the lookup table to link the content and ratings data and save it as a new file named ```banijay_op1data_content_ratings.csv```.

<details><summary> <mark>Reveal answer<mark> </summary> 
<p>
     In order to merge the two datasets, we will need to create a ```content_id``` column in the ratings data. This will help us link the two datasets and understand how the ratings data relates to the content data.

 We notice that we obtain ratings data every minute, and the content data lists out the start and end time of each fragment. Therefore, to match the datasets, we need to add the content id to each row in the ratings data based on the time the rating was taken (checking if that time lies between the start and end time given in the content data).

To achieve this, you will need to:
1. Create ```date_time``` columns in both the content and ratings data by combining the ```date``` and ```time``` columns.
2. Convert the ```date_time``` columns to ```datetime``` objects.
3. Create a ```content_id``` column in the ratings data by matching the ```date_time``` column in the ratings data to the ```start_time``` and ```end_time``` columns in the content data. Hint: notice that there are duplicate ```date_time``` values in the ratings data. You will need to use the ```unique()``` function to remove these duplicates and save the unique content date_times to a new data frame. 
4. For each unique ```date_time``` value in the ratings data, find the ```content_id``` that matches the ```date_time``` value. Hint: if you have converted ```date_time``` to a ```datetime``` object, you can use compare dates using simple operators such as ```>``` and ```<```.
5. Save the ratings data with the ```date_time``` and ```content_id``` columns to a new dataframe and consequently save it as a csv file and name it ```banijay_content_ratings_lookuptable.csv```. 
6. Using the lookup table, merge the ratings data with the lookup table data on the ```date_time``` column. Hint: you will need to use the ```merge()``` function.
7. Now that you have created a common key, you can merge the content data and ratings data on the ```content_id``` column. 
8. Save the merged data as a csv file and name it ```banijay_op1data_content_ratings.csv```.
9. Take a well-deserved break! You have completed the first use-case. </details>


## Use-case 2: Content Ratings Analysis

Now that you have linked the content and ratings data, you can perform some analysis on the data and generate reports that provide the client with insight. Please use visluizations to help you communicate your findings (as you did in Block A.). 

**I highly recommend you to use Python to generate the reports. However, if you are more comfortable using Power BI, you can use it to generate the reports.**

If you are using Python, please create a new Jupyter notebook and ensure that every analysis part you see below is it's own block.

Answer the following questions using ```kdh1000``` as an indicator for how well a show is performing, and focus on the ```totaal``` ratings type.

### Target Audience Analysis

Let's begin by looking at the target audience of the shows and understanding the audience's preferences and how they differ from each other.

1. What is the average rating for all shows across all target groups?
2. What is the average rating for all shows, per target group?


> Feel free to dive deeper into the data and come up with more interesting insights.

Please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.

### Content Analysis

> For the non-dutch speakers, you may choose to translate the data to English before proceeding with your analysis if you haven't already done so. Click [here](https://gist.github.com/nbhushan/a88bf700e54e99b1f259275ba6f89642) for an example of how to do so using Python.


1. Who are the most highly rated hosts?
2. What are the most highly rated shows and what are the most highly rated fragments in those shows?
3. For the top 5 fragments in terms of ratings, what were the keywords used in the content? Bonus: Try creating a word cloud to visualise the keywords.

> Feel free to dive deeper into the data and come up with more interesting insights.

Again, please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.


### Trend Analysis

In this section, we will look at the trends in the ratings data and try to understand how the ratings have changed over time.

1. What is the average rating for all shows, per month? Do you notice any trends?
2. What is the average rating for all shows, per day of the week? Do you notice any trends?
3. Repeat the above analysis, but for the target group with the highest average rating. Do you notice any trends?

> Feel free to dive deeper into the data and come up with more interesting insights.

Again, please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.


### The final report

If you are done with the use-cases, you can move on to documentation, ensure that you have saved and committed all your work to Github. Documentation is a very important part of the project, and you will need to ensure that you have a well-written report that clearly communicates your findings. Start writing the introduction and EDA section of your report. Do not wait until week 8 to start writing your report. You will need to write the report in stages, and you will need to submit your report in week 8. 


### Plagiarism

Please note that plagiarism is a serious offence. You are encouraged to use the internet to help you with your analysis, but you must ensure that you cite your sources.

However, if your code exactly resembles the code of another student, you will be reported to the board of examiners. You are encouraged to discuss the use-case with your peers, but you must ensure that you write your own code. If you are unsure about whether your code is similar to another student's code, please ask your mentor to review your code.
