---
sort: 13
---
# Data Lab: Creative Brief

If you had succesfully completed the workshops this week, you should
now have:

- [x] your Github contains the ```banijay_EDA``` folder with the
  - [x] ```banijay_data_content.ipynb``` notebook which reads in the raw content data, processes it, and saves the processed data.
  - [x] ```banijay_data_ratings.ipynb``` notebook which reads in the raw ratings data.
  - [x] A ```data``` folder containing the raw and processed data files.
  - [x] your Twitter developer account is activated and you have your API keys and tokens.

In **today's data lab**, we continue with the use-cases and the key addition for today is <mark>the use of social media data.</mark>

Before we start, please make sure you have read the sections on [The final report](https://adsai.buas.nl/Study%20Content/Programming/11.DataLabPR3.html#the-final-report) and [Plagiarism](https://adsai.buas.nl/Study%20Content/Programming/11.DataLabPR3.html#plagiarism) you can find in the bottom of this page.

**Let's get started: Keep the coffee flowing and the music playing!**

:thumbsup: :headphones:  :coffee:

## Use-case 1: Linking Content Data to Ratings Data

 As you may have noticed, the content data and ratings data are stored in different files. In order to perform any analysis, you will need to link the two datasets.

 However, merging datasets often requires a common key.
 For example, if we have one data frame containing ```student_id``` and ```student_name``` and another data frame containing ```student_id``` and ```student_grade```, we can merge the two data frames on the ```student_id``` column and create a dataframe containing the three columns which we can use for further analysis.

 Ideally, we would like to merge the content data and ratings data on the ```content_id``` column. However, the content data contains a ```content_id``` column, while the ratings data does not. Therefore, we need to figure out a way to still be able to merge the two datasets.

To solve this use-case, you will need to:

- [ ] create a lookup table that allows you link the content and the ratings data. In simpler terms, every ratings in the ratings data should be linked to a show, and specifically a fragment in the content data.
- [ ] use the lookup table to link the content and ratings data and save it as a new file named ```banijay_op1data_content_ratings.csv```.

## Use-case 2: Content Ratings Analysis

Now that you have linked the content and ratings data, you can perform some analysis on the data and generate reports that provide the client with insight. Please use visluizations to help you communicate your findings (as you did in Block A.).

**I highly recommend you to use Python to generate the reports. However, if you are more comfortable using Power BI, you can use it to generate the reports.**

If you are using Python, please create a new Jupyter notebook and ensure that every analysis part you see below is it's own block.

Answer the following questions using ```kdh1000``` as an indicator for how well a show is performing, and focus on the ```totaal``` ratings type.

### Target Audience Analysis

Let's begin by looking at the target audience of the shows and understanding the audience's preferences and how they differ from each other.

1. What is the average rating for all shows across all target groups?
2. What is the average rating for all shows, per target group?

> Feel free to dive deeper into the data and come up with more interesting insights.

Please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.

### Content Analysis

> For the non-dutch speakers, you may choose to translate the data to English before proceeding with your analysis if you haven't already done so. Click [here](https://gist.github.com/nbhushan/a88bf700e54e99b1f259275ba6f89642) for an example of how to do so using Python.

1. Who are the most highly rated hosts?
2. What are the most highly rated shows and what are the most highly rated fragments in those shows?
3. For the top 5 fragments in terms of ratings, what were the keywords used in the content? Bonus: Try creating a word cloud to visualise the keywords.

> Feel free to dive deeper into the data and come up with more interesting insights.

Again, please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.

### Trend Analysis

In this section, we will look at the trends in the ratings data and try to understand how the ratings have changed over time.

1. What is the average rating for all shows, per month? Do you notice any trends?
2. What is the average rating for all shows, per day of the week? Do you notice any trends?
3. Repeat the above analysis, but for the target group with the highest average rating. Do you notice any trends?

> Feel free to dive deeper into the data and come up with more interesting insights.

Again, please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.

## Use-case 3: Social Media Analysis

In this use-case, we will use the social media data to understand how the shows are performing on social media. In parcitular, we will look at the number of tweets and the number of retweets for each show, and calculate twitter engagement for each show and fragment

To solve this use-case, you will need to:

### Data Preparation

- [ ] prepare your environment (create a notebook, import the necessary libraries, etc.)
- [ ] read in the ```banijay_op1data_twitter_raw.json``` file from [here](https://edubuas.sharepoint.com/:u:/t/2022-23BFAI1.P2-01ADSAI/EUrNefNkNe1DkwIQQlZOmOIBwqyofoaSa6TVHkdmx60ZfQ?e=Ia8iYk) and store it in a dataframe.
- [ ] create a lookup table that allows you link the content and the social media data. In simpler terms, every tweet in the social media data should be linked to a show, and specifically a fragment in the content data.
- [ ] use the lookup table to link the content, ratings and social media data and save it as a new file named ```banijay_op1data_content_ratings_twitter.csv```.

### Analysis

- [ ] calculate the twitter engagement for each show and fragment.
- [ ] visualize the most popular shows and fragments based on twitter.
- [ ] investigate correlations between twitter engagement and ratings.
- [ ] investigate trends in twitter engagement based on Day of the show.

> Feel free to dive deeper into the data and come up with more interesting insights.

Again, please summarize your main findings either in your notebook, the notes file in your teams environment, or in a separate document. You will need these findings to help you write your final report.

### The final report

If you are done with the use-cases, you can move on to documentation, ensure that you have saved and committed all your work to Github. Documentation is a very important part of the project, and you will need to ensure that you have a well-written report that clearly communicates your findings. Start writing the introduction and EDA section of your report. Do not wait until week 8 to start writing your report. You will need to write the report in stages, and you will need to submit your report in week 8.

### Plagiarism

Please note that plagiarism is a serious offence. You are encouraged to use the internet to help you with your analysis, but you must ensure that you cite your sources.

However, if your code exactly resembles the code of another student, you will be reported to the board of examiners. You are encouraged to discuss the use-case with your peers, but you must ensure that you write your own code. If you are unsure about whether your code is similar to another student's code, please ask your mentor to review your code.
