---
sort: 19
---
# Gym Environment Wrapper Planning 


- What is the goal of the wrapper?
- What are the inputs of the wrapper?
- What are the outputs of the wrapper?
    - Observation
    - Reward
    - Done

## RoboSuite Gym Environment Wrapper



# Remote Training Jobs: Pendulum Control with RL

Use the Stable Baselines 3 library to train a reinforcement learning agent to control the pendulum environment.

Use the following code to train the agent:

```python
import gym
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.callbacks import EvalCallback

# Create a vectorsied environment
env = make_vec_env("Pendulum-v1", n_envs=4) #you can try using more than 4 environments if you have a powerful computer

# Create the model
model = PPO("MlpPolicy", env, verbose=1)

# Train the model
model.learn(total_timesteps=10000, progress_bar=True) # you will need to train for at least 500000 timesteps

# Evaluate the model
mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)

print(f"mean_reward:{mean_reward:.2f} +/- {std_reward}")

# Demo the model
env = gym.make("Pendulum-v1")
obs = env.reset()
for i in range(200):
    action, _states = model.predict(obs, deterministic=True)
    obs, rewards, dones, info = env.step(action)
    env.render()
```

ARGPARSE