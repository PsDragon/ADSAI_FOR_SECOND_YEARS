# Robotic Simulation Primer

## Why Simulation?
Robotic manipulation tasks are complex and often involve expensive equipment that can be both fragile (high precision sensors) and dangerous to work with (extremely powerful actuators). It is important to be sure that a new control algorithm will work as expected before deploying it on real hardware. Deploying a controller in simulation first is a much safer (and cheaper) way of designing and developing new control algorithms. Simulation allows us to test controllers without risk of damaging the equipment or environmnet in which it operates, like in the gifs below:

<div style="text-align: center"> 
<img src="Images/RobotCrash.gif" height="200" />
<img src="Images/RobotHumanCrash.gif" height="200" />

[Source1](https://www.youtube.com/watch?v=7FwdMjYUyKM) 
[Source2](https://www.youtube.com/watch?v=LzZmPRm4rII) 
</div>

There many robot simulators each with a different focus, strengths, and weaknesses. The list below shows some common robot simulation environments, with links to their websites:

- [Gazebo](https://gazebosim.org/home)
- [Webots](https://cyberbotics.com/)
- [RoboSuite](https://robosuite.ai/docs/overview.html)
- [Robot Studio](https://new.abb.com/products/robotics/robotstudio)
- [RoboDK](https://robodk.com/index)

Lightweight physics engines that can be setup for robotic simulation:
- [MuJoCo](https://mujoco.org/)
- [PyBullet](https://pybullet.org/wordpress/)

We will be working with Robosuite as it is open source and the most suited to our application, but feel free to check out some of the other options.


## What is RoboSuite? <img src="Images/robosuite.jpg" height="30" />

Robosuite is a robotic simulation environment built on top of the MuJoCo physics engine and compatible with then Open AI Gym format for reinforcement learning and other reinforcement learning libraries like Stable Baselines. The physics engine models realistic motion and contents while still being lightweight enough to run multiple instances in parallel. Robosuite focuses on simulation of robotic arm manipulation environments and tasks. 3D rendering is included for integration of computer vision workflows into these tasks. Some key features are highlighted in the video below.

<div style="text-align: center"> 
<iframe height="315" width="550"
src="Videos/robosuite-video-faster.mp4" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen></iframe>
</div>


## Installing RoboSuite

Robosuite and the packages it relies on (MuJoCo) were designed to run in a Linux environment. We will be installing Robosuite on Ubuntu using WSL2. 

1. Open an Ubuntu Terminal
2. Check that the Ubuntu packages are up to date

        sudo apt update

3. Install Pre-requisites

        sudo apt install curl git libgl1-mesa-dev libgl1-mesa-glx libglew-dev \
         libosmesa6-dev software-properties-common net-tools unzip vim \
         virtualenv wget xpra xserver-xorg-dev libglfw3-dev patchelf

4. Install Robosuite

        pip install robosuite

5. Test the installation

        python robosuite/demos/demo_random_action.py

You may need to navigate to the directory where robosuite was installed.

<div style="text-align: center"> 
<img src="Images/RSeg.gif" height="400" />
</div>

Source: [Robosuite Website](https://robosuite.ai/docs/installation.html)

## Collecting Image Data

1. Import Libraries

        import numpy as np
        import robosuite as suite
        import matplotlib.pyplot as plt

2. Create the Environment

        # create environment instance
        env = suite.make(env_name="Lift", # try with other tasks like "Stack","Door", "PickPlace"
                        robots="Panda",   # try with other robots like "Sawyer" and "Jaco"
                        has_renderer=False,
                        has_offscreen_renderer=True,
                        use_camera_obs=True,                  
                        camera_segmentations = 'element' # if you want segmented images as well
                        )

3. Initialize Data Storage Variables

4. Retrieve and Interrogate the Observation

        obs = env.reset() 

>>> Plot a test image


5. Data Collection Loop

        obs = env.reset() 


6. Save to disk



