# Introduction to Robotics
Automation of manual, repetitive, and dangerous tasks is carried out across many industries in order to reduce labour costs, increase efficiency, and improve working conditions. The addition of data driven techniques like computer vision and reinforcement learning allow for more complex tasks to be automated using robots.   

The focus of this knowledge module is on understanding the basic principles of robotics.

After this module, you will be able to:
- [ ] Develop an understanding of what robotics is and its current and future applications.
- [ ] Develop an understanding of the purpose of the different components of robotic systems.
- [ ] Describe the location and orientation of objects in a 3D space.

## What is Robotics?
Robotics is the study of robotic systems, including their design, manufacture and control (operation, and use). A few definitions of robots, or robotic systems are presented below:

- Robotic systems are defined as systems that provide intelligent services and information by interacting with their environment, including human beings, via the use of various sensors, actuators and human interfaces. [( Object Management Group, 2005)](https://www.igi-global.com/dictionary/robotic-systems/46626#:~:text=1.,Object%20Management%20Group%2C%202005%20)
- Robots are machines that can substitute for humans and replicate human actions. [(Wikipedia)](https://en.wikipedia.org/wiki/Robotics)
- A robot is a machine, especially one programmable by a computer, capable of carrying out a complex series of actions automatically. (Oxford Dictionary)
- A robot is an autonomous machine capable of sensing its environment, carrying out computations to make decisions, and performing actions in the real world. [(IEEE)](https://robots.ieee.org/learn/what-is-a-robot/)

The last definition is very general, but it best captures the broadness of the field. Especially when considering that machines as complex as Boston Dynamics [Atlas](https://www.bostondynamics.com/atlas) and a [Tesla on Autopilot](https://www.tesla.com/autopilot) all the way down to something as seemingly simple as a [Roomba](https://www.youtube.com/watch?v=_RvnlDNTo0E) can be considered to be robots.

<div style="text-align: center"> 
<iframe width="560" height="315" src="https://www.youtube.com/embed/uNfUAJBuZ0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

We will be focusing on developing control algorithms for robots, but it is important to have an understanding of what they are and what components they are comprised of in order to develop functional and efficient control systems. 

<div style="text-align: center"> 
<iframe width="560" height="315" src="https://www.youtube.com/embed/_U21fT8VLp0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

## Applications of Robotics
Robots are used in a wide variety of applications, including manufacturing, construction, agriculture, and healthcare. Robots are most useful for tasks that are repetitive, dangerous, or require precision.

The following are some examples of the applications of robotics to these kinds of tasks (This is not an exhaustive list):

- Industrial Robots in Manufacturing: Manufacturing and heavy industry were some of the first industries to adopt robots. Robots are used in production lines across many industries, including automotive, electronics, and food processing. They are programmed to perform a variety of tasks, including welding, painting, and assembly. The video below shows the use of robots on the BMW production line:

<div style="text-align: center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/P7fi4hP_y80" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

- Surgery: Robots are used in surgery to perform minimally invasive procedures. They are used to perform tasks that are difficult for humans to do because they require extremely high levels of precision and stability, such as removing tumours from the brain. The robot is not autonomous, but it is controlled by a surgeon. The surgeon is able to control the robot using a custom interface, and the robot is able to provide feedback to the surgeon about the position of the surgical tools. This means that the surgeon does not even have to be in the same room as the patient, and can perform the surgery remotely. The video below shows the use of a robot in a minimally invasive surgery:

<div style="text-align: center">
<iframe width="712" height="315" src="https://www.youtube.com/embed/kYmtvLNNqHI" title="Robotic Surgery: When Less is More" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

- Bomb Disposal: Tasks that are dangerous for humans to perform are also good candidates for robots. Robots are used to safely retrieve and dispose of or disarm bombs. These robots are operated remotely as in the image below showing the use of a robot to safely dispose of a bomb:

<div style="text-align: center">
<img src="Images/bombdisp.webp" height="400" />

[source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.popsci.com%2Fgerman-researchers-want-bomb-squad-robots-to-see-inside-suitcases%2F&psig=AOvVaw2LEKLUNmFn3z0DtIwLbyQv&ust=1669112398763000&source=images&cd=vfe&ved=0CBAQjRxqFwoTCMjHqK-Gv_sCFQAAAAAdAAAAABAP)
</div>

- Warehousing: Relatively simple tasks that are repetitive and require precision are also good candidates for robots. Robots are used in warehouses to pick and place items, and to move items around the warehouse. Robots are not restricted to ground operations, some robots can fly (these are often referred to as drones, or unmanned aerial vehicles (UAVs)). Systems that make use of small multirotor drones that fly around the warehouse and scan barcodes on items are used to track the location of items in the warehouse are in active development. The gif below shows the use of robots in an amazon warehouse, and the video below shows the use of a drone in a warehouse:

<div style="text-align: center">
<img src="Images/amazon_warehouse_robot.gif" height="314" />

<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.homemadetools.net%2Fforum%2Famazon-warehouse-robot-gif-54074&psig=AOvVaw3YcmisRZsKn0hbXo5voDVf&ust=1669112767078000&source=images&cd=vfe&ved=0CBAQjRxqFwoTCOj53N6Hv_sCFQAAAAAdAAAAABAV">Source</a>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PETeQDif2OU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>   

- Delivery: Robots are also being tested for delivery of packages. Both aerial and ground robots are being tested for this purpose. The videos below show the use of a ground robot and an aerial robot for delivery:

<div style="text-align: center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/t5yI7HrzUUk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="610" height="343" src="https://www.youtube.com/embed/3bDyeUiWL3M" title="Watch how Amazon is preparing for safe drone delivery" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

- Household: This is an example that you all should have seen in action on campus. BUas has been using autonomous cleaning robots to keep the floors clean in the buildings. The robots are able to navigate around the buildings and clean the floors, they are able to avoid obstacles and navigate around people. The same technology is used in robots equipped with blades instead of brushes to cut the grass in parks and lawns. 

- Autonomous Vehicles: Some of the most complex robotic systems in use today are autonomous/semi-autonomous vehicles these robots are required to perform several complex tasks in a complex dynamic environment. It may be hard to think of these 'cars' as robots but the have sensors to perceive the environment, they process the sensor data and use it to make decisions on what actions to take next in order to accomplish a given task. At this point these systems are only semi-autonomous, except for in very control conditions.   [Tesla](https://www.tesla.com/autopilot) and [Waymo](https://waymo.com/) are leading the way in the development of autonomous vehicles, albeit with very different approaches.

- General Purpose: what most people think of when they hear the word robot are general purpose robots. These robots are designed to be able to perform a wide variety of tasks. They are often humanoid in appearance, and are able to move around on two (sometimes four) legs. They are able to perform tasks such as walking, running, jumping, climbing stairs, and lifting objects. They are also able to perform tasks such as speech recognition, facial recognition, and object recognition. These robots are often used in research and development, and are not yet widely available for commercial use. They are particularly difficult to develop and program because they are able to perform a wide variety of tasks, and are able to adapt to new situations. Some examples of general purpose robots are the [Boston Dynamics Spot](https://www.bostondynamics.com/products/spot), [Boston Dynamics Atlas](https://www.bostondynamics.com/atlas), and most recently the [Teslabot](https://spectrum.ieee.org/tesla-optimus-robot) which is a humanoid robot that can be used to perform tasks in the Tesla factory.

<div style="text-align: center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/wXxrmussq4E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/ODSJsviD_SU?start=2850" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

As we have seen above robots can be autonomous or teleoperated. Autonomous robots are able to perform tasks without human intervention. Teleoperated robots are controlled by a human operator. In this course, we will be focusing on the control of autonomous robots. We will be developing control algorithms that allow the robot to perform tasks without human intervention. In the next section, we will look at the components of a robot and how they are used to perform tasks.

## Components of a Robotic System

##### INSERT WAREHOUSE ROBOT VIDEO/GIF

### Environment
The environment is the world in which the robot operates. The robot needs to be able to perceive it's surroundings and interact which objects within the environment in order to carry out tasks. If we consider the example of an autonomous warehouse robot the environment would be the area in which the robot operates (walls, floor, roof) and all objects (shelves, boxes, people). The robot needs to be able to perceive the environment in order to navigate and interact with objects within the environment.

### Sensors
Sensors are the means by which a robot perceives it's environment. The complexity and number of sensors is often directly related to the complexity of the required task. In this example the robot may need to know its location within the environment (warehouse), the distance to nearby objects and possibly what these objects are. A GPS could be used to detect the robots location, and a scanning LiDAR could be used to provide the distances to all nearby objects in the desired field of view. In order to determine what the objects a camera could be used in conjunction with a computer vision algorithm for object detection and classification. 

Table of sensors for common perception tasks:

| Task | Sensor | Sensor output |
| --- | --- | --- |
| Location | GPS | 3D position |
| Distance | LiDAR | 3D point cloud |
| Distance | Ultrasonic | Single Distance Value |
| Distance | Radar | 3D point cloud |
| Distance | Camera | 2D image |
| Orientation | Inertial Measurement Unit | 3D position and orientation |
| Orientation | Gyroscope | 3D orientation |
| Orientation | Magnetometer | 3D orientation |
| Object Detection | Camera | 2D image |
| Object Detection | LiDAR | 3D point cloud |
| Motion | Accelerometer | 3D acceleration |
| Motion | Gyroscope | 3D angular velocity |
| Motion and Orientation | Inertial Measurement Unit | 3D position, orientation, acceleration, angular velocity |

### Actuators


Table of common actuators:

| Actuator | Description | Example |
| --- | --- | --- |
| Motors | Motors are used to provide motion to the robot. Motors can be used to provide linear motion (e.g. wheels) or rotational motion (e.g. motors for a robotic arm). | [Wheels](https://www.youtube.com/watch?v=ZJ2J8ZQ9Z0E) |


### Actuators and Effectors
Actuators are the means by which a robot interacts with its environment. These are generally mechanical, or electro-mechanical devices which allow the robot or part of the robot to move. In the case of the warehouse robot the actuators would be the motors that spin its wheels (if it has wheels). If the robot was fitted with a robotic arm to grasp objects that would the arm linkages themselves would be moved by actuators. These would be either electric motors or hydraulic cylinders depending on the arm design. The part of the arm that actually grasps objects (the gripper) is known as an effector, as it physically affects the environment. 


LABELLED GIF OF SPOT OPENING A DOOR 


### Control Hardware and Algorithms
Both Sensors and actuators are required for an autonomous or semi-autonomous robotic system to accomplish a task within the environment, however there is still one piece missing. The robot needs to be able to process the signals coming in from the sensors and then use this information to decide on its next action. That decision then needs to be turned into appropriate signals to move the actuators in a useful manner. This process is handled by the control algorithm which is run on the control hardware. The hardware and algorithms required will also vary in complexity depending on the complexity of the task. (Roomba vs tesla?).

General Edge Computing: 
- Arduino
- Raspberry Pi
- Nvidia Jetson

Purpose built:
- Pixhawk
- Nvidia Drive
- Tesla Onboard computer 

More powerful options:
- Workstation
- Cloud Computing

Control algorithms are the software that runs on the control hardware. They are responsible for processing the sensor data and deciding on the next action to take. The control algorithm is often the most complex part of a robotic system, as it needs to be able to process the sensor data and make decisions based on that data. We will look at control algorithms in more detail in Robotics II and in the Reinforcement learning sections.

## Co-ordinate Systems
Co-ordinate systems are used to describe an objects position and orientation in space. There are many different co-ordinate systems, but the most common are the Cartesian, Polar and Spherical co-ordinate systems. 

- Cartesian

The Cartesian co-ordinate system is the most common co-ordinate system used in robotics. It is a right handed co-ordinate system with the origin at the centre of the system. The x-axis is horizontal and points to the right, the y-axis is vertical and points up, and the z-axis points out of the page.

- Polar

The polar co-ordinate system is a two dimensional co-ordinate system. The origin is the centre of the system and the x-axis is the radius of the circle. The y-axis is the angle of the point from the x-axis.

- Spherical

The spherical co-ordinate system is a three dimensional co-ordinate system. The origin is the centre of the system and the x-axis is the radius of the sphere. The y-axis is the angle of the point from the x-axis and the z-axis is the angle of the point from the xy-plane.

### Translation

Translation is the movement of an object from one point to another. In the case of a robot this would be the movement of the robot from one location to another. In the case of a robot arm this would be the movement of the end effector from one location to another. 

Translation in a 3D Cartesian co-ordinate system is described by the x, y and z components of the translation. The x component is the distance moved in the x direction, the y component is the distance moved in the y direction, and the z component is the distance moved in the z direction. Consider the following example: 

A robot is located at the origin of a Cartesian co-ordinate system. The robot is commanded to move 1m in the x direction, 2m in the y direction and 3m in the z direction. The robot will move to the point (1, 2, 3) in the Cartesian co-ordinate system.

INSERT GIF OF ROBOT MOVING 1M IN X, 2M IN Y, 3M IN Z

The origin is the point (0, 0, 0) in the Cartesian co-ordinate system. The x-axis is the line x = 0, the y-axis is the line y = 0, and the z-axis is the line z = 0. The x-axis is horizontal and points to the right, the y-axis is vertical and points up, and the z-axis points out of the page. The origin is the centre of the Cartesian co-ordinate system and can be positioned anywhere in space. In the case of RoboSuite the origin is located at ...

You should always be aware of the co-ordinate system you are using and the position of the origin. If you are using a different co-ordinate system to the one you are used to you may need to convert between the two.

### Rotation

Rotation is the movement of an object around a point. In the case of a robot this would be the rotation of the robot around a point. In the case of a robot arm this would be the rotation of the end effector around a point.

Rotation in a 3D Cartesian co-ordinate system is described by the x, y and z components of the rotation. The x component is the angle of rotation around the x axis, the y component is the angle of rotation around the y axis, and the z component is the angle of rotation around the z axis. Consider the following example:

A robot is located at the origin of a Cartesian co-ordinate system. The robot is commanded to rotate 90 degrees around the x axis, 180 degrees around the y axis and 270 degrees around the z axis. The robot will rotate to the point (90, 180, 270) in the Cartesian co-ordinate system.

INSERT GIF OF ROBOT ROTATING 90 DEGREES AROUND X, 180 DEGREES AROUND Y, 270 DEGREES AROUND Z

If we combine translation and rotation we can fully describe the movement of an object from one point to another in 6 degrees of freedom. The robot will move to the point (1, 2, 3) in the Cartesian co-ordinate system and rotate to the point (90, 180, 270) in the Cartesian co-ordinate system.

INSERT GIF OF ROBOT ROTATING 90 DEGREES AROUND X, 180 DEGREES AROUND Y, 270 DEGREES AROUND Z

### Pose

Pose is the position and orientation of an object. In the case of a robot this would be the position and orientation of the robot. In the case of a robot arm this would be the position and orientation of the end effector.

If we combine translation and rotation we can fully describe the movement of an object from one point to another in 6 degrees of freedom. The robot will move to the point (1, 2, 3) in the Cartesian co-ordinate system and rotate to the point (90, 180, 270) in the Cartesian co-ordinate system.

INSERT GIF OF ROBOT ROTATING 90 DEGREES AROUND X, 180 DEGREES AROUND Y, 270 DEGREES AROUND Z

- Euler Angles - Roll, Pitch, Yaw

Euler angles are a common way to describe the orientation of an object. Roll is the rotation around the x-axis, pitch is the rotation around the y-axis, and yaw is the rotation around the z-axis. The pose of an object in 3D space can be represented by the following vector:

$$ pose = \begin{bmatrix} x \\ y \\ z \\ roll \\ pitch \\ yaw \end{bmatrix} $$

The main draw back of using Euler angles is that they are not unique. For example, the pose (1, 2, 3, 0, 0, 0) and the pose (1, 2, 3, 360, 360, 360) are the same pose. This can cause problems when using Euler angles to describe the pose of an object. Gimbal lock is another problem with Euler angles. Gimbal lock occurs when the pitch angle is 90 degrees or -90 degrees. When the pitch angle is 90 degrees or -90 degrees the roll and yaw angles become undefined. This is just one example of when gimbal lock can occur. There are many other examples of when gimbal lock can occur.

- Quarternions

Quarternions are another way to describe the orientation of an object. Quarternions are a four dimensional vector. Quarternions are a more complex way to describe the orientation of an object, but they do not suffer from the same problems as Euler angles. Quarternions are unique and do not suffer from gimbal lock. The pose of an object in 3D space using quarternions can be represented by the following vector:

$$ pose = \begin{bmatrix} x \\ y \\ z \\ q_x \\ q_y \\ q_z \\ q_w \end{bmatrix} $$

For more details on quartenions and how they work please see the following tutorial: [Tutorial series on Quarternions](https://eater.net/quaternions)

Quarternions are used in RoboSuite to describe the orientation of objects and robots. 

### Degrees of freedom

Degrees of freedom is a measure of the number of independent variables that can be used to describe the position and orientation of an object. In the case of a robot this would be the number of independent variables that can be used to describe the position and orientation of the robot. In the case of a robot arm this would be the number of independent variables that can be used to describe the position and orientation of the end effector. With a robot arm the number of degrees of freedom is equal to the number of joints in the arm. We will be worling with 7DOF robot arms in RoboSuite. That means that we can use 7 independent variables to describe the position and orientation of the end effector.

https://www.youtube.com/watch?v=vOFM8eG8kVc

## Work Envelope

A robots work envelope is the space that the robot can move in. The work envelope of a robot is defined by the maximum and minimum values for each of the degrees of freedom. In the case of a robot arm the work envelope is defined by the maximum and minimum values for each joint. It is important to understand the work envelope of a robot before you start programming it. If you do not understand the work envelope of a robot you could damage the robot or the environment.

A few examples of work envelopes are shown below:

INSERT GIF OF ROBOT ARM MOVING IN WORK ENVELOPE CLIPPED FROM VIDEO BELOW

This video explains the concept in more detail:

<iframe width="560" height="315" src="https://www.youtube.com/embed/_canCYWZPsc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Other Cool Videos:

https://www.youtube.com/watch?v=N_XneaFmOmU&t=32s
https://www.youtube.com/watch?v=hoY2YxLGV98
https://www.youtube.com/watch?v=11Yv_KhCjjU

<div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;; background-color: #fcf8e3; border-color: #faebcc;">
Disclaimer: Some of this module was written using AI suggestions by GitHub Copilot.   
</div>


