# Robotic Simulation: RoboSuite Basics

RoboSuite is a Python library for simulating robotic systems. It is based on the MuJoCo physics engine, and is designed to be easy to use and extend. RoboSuite is a part of the D4RL project, which is a collection of datasets and benchmarks for deep reinforcement learning in robotics. 

This knowledge module will cover the basics of using RoboSuite to simulate a robotic arm. The full documentation for RoboSuite can be found [here](https://robosuite.ai/docs/index.html). 

## Robosuite Pre-built Environments and Tasks

RoboSuite comes with a number of pre-built environments and tasks. These environments are designed to be easy to use and extend. The table below lists the pre-built environments and tasks in RoboSuite that we will be working with. A full list of the pre-built environments and tasks can be found [here](https://robosuite.ai/docs/modules/environments.html#task-models).

| Environment | Description |
| --- | --- |
| Lift | Lift a block from a table to a goal height |
| Stack | Stack a block on top of another block |
| PickPlace | Pick up a 4 consumer goods objects and place them in corresponding bins |
| PickPlaceCan | A simpler version of the PickPlace task where you need to pick up a can and place it in a bin |

You define the environment you want to use by passing the name of the environment to the `make` function. For example, to create the `Lift` environment, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift")
```

## Robots

RoboSuite currently supports seven commercially-available manipulator robot models.

| Robot | Description |
| --- | --- |
| Panda | A 7-DoF and relatively new robot model produced by Franka Emika, and boasts high positional accuracy and repeatability. A common choice for both simulated and real-robot research. The default gripper for this robot is the PandaGripper, a parallel-jaw gripper equipped with two small finger pads, that comes shipped with the robot arm. |
| Sawyer | Rethink Robotic’s 7-DoF single-arm robot, which also features an additional 8th joint (inactive and disabled by default in robosuite) for swiveling its display monitor. Along with Panda, Sawyer serves as the second testing robot for our set of benchmarking experiments. Sawyer’s default RethinkGripper model is a parallel-jaw gripper with long fingers and useful for grasping a variety of objects. |
| LBR IIWA 7 | One of KUKA’s industrial-grade 7-DoF robots, and is equipped with the strongest actuators of the group, with its per-joint torque limits exceeding nearly all the other models in robosuite by over twofold! By default, IIWA is equipped with the Robotiq140Gripper, Robotiq’s 140mm variation of their multi-purpose two finger gripper models. |
| Baxter | An older but classic bimanual robot originally produced by Rethink Robotics but now owned by CoThink Robotics, and is equipped with two 7-DoF arms as well as an addition joint for controlling its swiveling display screen (inactive and disabled by default in robosuite). Each arm can be controlled independently in, and is the single multi-armed model currently supported in robosuite. Each arm is equipped with a RethinkGripper by default. |
| Jaco | A popular sleek 7-DoF robot produced by Kinova Robotics and intended for human assistive applications. As such, it is relatively weak in terms of max torque capabilities. Jaco comes equipped with the JacoThreeFingerGripper by default, a three-pronged gripper with multi-jointed fingers. |
| UR5e | Universal Robot’s newest update to the UR5 line, and is a 6-DoF robot intended for collaborative applications. This newest model boasts an improved footprint and embedded force-torque sensor in its end effector. This arm also uses the Robotiq85Gripper by default in robosuite. |
| Kinova Gen3 | Kinova’s newest 7-DoF robot, with integrated sensor modules and interfaces designed for research-oriented applications. It is marginally stronger than its Jaco counterpart, and is equipped with the Robotiq85Gripper, Robotiq’s 85mm variation of their multi-purpose two finger gripper models. |

<div style="text-align: center">
<img src="https://robosuite.ai/docs/images/robot_model_Panda.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_Sawyer.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_IIWA.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_Baxter.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_Jaco.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_UR5e.png" height="120" />
<img src="https://robosuite.ai/docs/images/robot_model_Kinova3.png" height="120" />
</div>

You can see more details about the robots in RoboSuite [here](https://robosuite.ai/docs/modules/robots.html).

We will be using the `Panda` robot for this knowledge module. You can create the `Panda` robot by passing the name of the robot to the `make` function. For example, to create the `Panda` robot, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift", robots="Panda")
```

## Rendering

RoboSuite supports rendering the simulation using the MuJoCo OpenGL renderer. You can enable rendering by passing `has_renderer=True` to the `make` function. This will render the simulation on screen. For example, to create the `Lift` environment with rendering enabled, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift",
                 robots="Panda",
                 has_renderer=True)
```

There is also an off-screen renderer that can be used to render the simulation without displaying it on screen. You can enable the off-screen renderer by passing `has_offscreen_renderer=True` to the `make` function. If you do this you need to also set `has_renderer=False`. For example, to create the `Lift` environment with the off-screen renderer enabled, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift",
                 robots="Panda",
                 has_renderer=False,
                 has_offscreen_renderer=True)
```

Using an off-screen renderer allows you to access the image data from any camera sensors that are attached to the robot. You can access the image through the returned observation dictionary if the `use_camera_obs` flag is set to `True` when creating the environment. For example, to create the `Lift` environment with the off-screen renderer enabled and camera observations enabled, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift",
                 robots="Panda",
                 has_renderer=False,
                 has_offscreen_renderer=True,
                 use_camera_obs=True)
```

## Useful Environment Parameters

There are a number of parameters that can be passed to the `make` function to configure the environment. Some of the relevant parameters are listed below. A full list of parameters can be found [here](https://robosuite.ai/docs/modules/environments.html).

### Horizon

The `horizon` parameter specifies the maximum number of steps that the environment will run for. If the environment reaches the horizon before the task is completed, the environment will reset. The default value for the `horizon` parameter is 1000.

### Control Frequency

The `control_freq` parameter specifies the frequency at which the robot will be controlled. The default value for the `control_freq` parameter is 20. This means that the robot will be controlled 20 times per second.

### Gripper Types

The `gripper_types` parameter specifies the type of gripper that will be used by the robot. The default value for the `gripper_types` parameter is `default`. This means that the robot will use the default gripper that comes with the robot. If you want to use a different gripper, you can pass the name of the gripper to the `gripper_types` parameter. For example, to create the `Lift` environment with the `Panda` robot and the `Robotiq85Gripper` gripper, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift",
                 robots="Panda",
                 gripper_types="Robotiq85Gripper")
```

## Observations

The environment returns observations to the agent. The observations are returned as a dictionary. The keys of the dictionary are the names of the observations. The values of the dictionary are the values of the observations. The observations that are returned depend on the environment and the parameters that are passed to the `make` function. The simplest way to see the observations that are returned is to print the observations after resetting the environment. For example, to print the observations for the `Lift` environment, you would use the following code:

```python
import robosuite as suite

env = suite.make(env_name="Lift",
                 robots="Panda", 
                 use_camera_obs = False,
                 use_object_obs = False)

obs = env.reset()
print(obs)
```

Try running the code above and see what observations are returned. 

Now try changing the `use_camera_obs` and `use_object_obs` parameters to `True` one at a time and see what observations are returned.

Next try changing the environment to `Stack` and see what observations are returned.

## Controllers and Actions

The actions that can be passed to an environnment will depend on the controller that is used by the robot. The controller that is used by the robot can be specified by passing the name of the controller to the `controller_configs` parameter. The default value for the `controller_configs` parameter is `default`. This means that the robot will use the default controller that comes with the robot. 

The `default` controller for the `Panda` robot allows you to specify the desired change in position for each of the 7 joints and the gripper. The actions that are passed to the environment should be a list of 8 values. The first 7 values should be the desired change in position for each of the 7 joints. The last value should be the desired change in position for the gripper.

If you want to use a different controller, you can pass the name of the controller to the `controller_configs` parameter. For example, to create the `Lift` environment with the `Panda` robot and the `OSC_POSE` controller, you would use the following code:

```python
import robosuite as suite
from robosuite.controllers import load_controller_config

# load default controller parameters for Operational Space Control (OSC)
controller_config = load_controller_config(default_controller="OSC_POSE")

env = suite.make(env_name="Lift",
                 robots="Panda",
                 controller_configs=controller_config)
```

The `OSC_POSE` controller allows you to specify the desired position and orientation for the end effector. The actions that are passed to the environment should be a list of 7 values. The first 3 values should be the desired change in position (`[x, y, z]`) for the end effector. The second values should be the desired change in orientation (`[roll, pitch, yaw]`) for the end effector. The last value should be the desired change in position for the gripper.

The full list of controllers that are available can be found [here](https://robosuite.ai/docs/modules/controllers.html).

### Example of the default controller



### Example of the OSC_POSE controller


<div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;; background-color: #fcf8e3; border-color: #faebcc;">
Disclaimer: Some of this module was written using AI suggestions by GitHub Copilot.   
</div>