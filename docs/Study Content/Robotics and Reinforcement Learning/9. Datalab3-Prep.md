---
sort: 17
---
# DataLab Prep: Using an Object Detection Model for Inference

For tomorrows datalab you will be using your object detection models to detect and objects in a RoboSuite environment. 

## Object Detection Training Recap

If you need a refresher on how to train a YOLOv5 object detection model you can follow the steps in this tutorial: [YOLOv5 - Train Custom Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)

## Object Detection Inference

You will need to load your trained model and feed it images from the RoboSuite environment. To load your model you can use the following code:

```python
import torch

# Load YOLOv5 model for the torch hub, and import your weights
model = torch.hub.load('ultralytics/yolov5', 'custom', path='path/to/best.pt')
```
You will need to provide the path to your trained weight file, this will differ depending on where the file is saved on your computer.

Once you have created an instance of the model you can use it for inference by passing it an image. The image should be a numpy array with shape `(height, width, channels)`. The image should be in RGB format. You can use the following code to get an image from the RoboSuite environment:

```python
import robosuite as suite
from robosuite.utils import SimulationVideoWrapper

# Create the environment
env = suite.make(
    "Lift",
    robots="Panda",
    has_renderer=True,
    has_offscreen_renderer=False,
    use_camera_obs=False,
)

# Reset the environment
env.reset()

# Get the image from the environment
image = env.sim.render(camera_name="agentview", height=256, width=256, depth=False)
```

OR:

```python
import robosuite as suite

# Create the environment
env = suite.make(
    "Lift",
    robots="Panda",
    has_renderer=False,
    has_offscreen_renderer=True,
    use_camera_obs=True,
)

# Reset the environment
obs = env.reset()

# Get the image from the observation
image = obs['agent_image']
```

Once you have an image you can pass it to the model for inference:

```python
# Run inference
results = model(image)
```

You can show the results or print a pandas dataframe of the results using the following code:

```python
# Show the results
results.show()

# Print the results
results.xyxy[0]
```

<div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #31708f; background-color: #d9edf7; border-color: #bce8f1;">
Think about how you can use the results to control the robot in the environment.
</div>

Take a screenshot of the results and paste it into the cell below and add it to your learning log as evidence.