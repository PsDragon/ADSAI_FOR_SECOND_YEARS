---
sort: 18
---
# PID with Vision

## Goal for the day:

- Develop a vision system using object detection to estimate the position of a cube in a 3D environment.
- Integrate the PID controller with the vision system to control the position of the end effector of the robotic arm.

### Expected Output

- A gif of a robot arm lifting a block, with vision data overlayed on the image

## General Plan:
- [ ] Discuss any questions about the knowledge modules so far
- [ ] Create a plan for collecting training data
- [ ] Collect training data for co-ordinate estimation
- [ ] Train a model to estimate the position of the cube
- [ ] Use the RoboSuite environment to simulate a robotic arm lifting a block, using a controller that you design that uses the vision system to estimate the position of the cube.

## Estimating the Position of a cube in a 3D Environment

### Collecting Training Data

Think about the following questions when planning how to collect training data:

- What is the input to the model? (Hint: What information about the objects would we have access to in the real world?)
- What is the output of the model? (Hint: what is the current input to the PID controller?)
- How much training data do we need?
- How should the data and labels be stored?

### Creating a Model

These instructions are for PyTorch, but you can use any framework you like.

- Create a model class that inherits from `nn.Module`
- Define the layers of the model
- Define the forward pass

Here is an example of a model that takes in an image and some other features (bounding box coordinates and on-hot encoded object class) and outputs the position and yaw angle of the object in 3D space.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class Coord_Predictor(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 64, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(64, 128, 5)
        self.fc1 = nn.Linear(79360, 512)
        self.fc2 = nn.Linear(512, 64)
        self.fc3 = nn.Linear(64+8, 32)
        self.fc4 = nn.Linear(32, 4)

    def forward(self, x, x2):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        concx = torch.cat((x,x2),dim=1) #concatenate the additional features
        x = F.relu(self.fc3(concx)) 
        x = self.fc4(x)
        return x
```
 You can use this model as a starting point and modify it to suit your needs. It can definitely be improved!

### Training a Model

These instructions are for PyTorch, but you can use any framework you like.
1. Create a model instance

```python
model = Predictor()
```
2. Create a loss function

```python
criterion = nn.MSELoss()
```
3. Create an optimizer

```python
optimizer = optim.Adam(model.parameters(), lr=0.0001)
```
4. Load your training data (inputs) and labels (targets)

5. Fetch a batch of training data and labels (a btach size of 32 or 64 is a good place to start)

6. Zero gradients

```python
optimizer.zero_grad()
```
7. Forward pass one batch

```python
output = model(input)
```
8. Calculate loss

```python
loss = criterion(output, target)
```
9. Backward pass and step the optimizer - update weights

```python
loss.backward()
optimizer.step()
```
10. Print training statistics (Optional)

```python
# print statistics
running_loss += loss.item() #need to set running_loss = 0.0 before the loop
#print(running_loss)
if batch % 10 == 9:    # print every 10 batches
    print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / 10:.8f}')
    running_loss = 0.0
```
11. Repeat 5-10 until all batches have been processed
12. Repeat 11 for all epochs (10 is a good place to start)

### Evaluating a Model

These instructions are for PyTorch, but you can use any framework you like.

- Create a model instance and load the weights

```python
model = Predictor()
state_dict = torch.load('weights.pt')
model.load_state_dict(state_dict)
```	
- Set the model to evaluation mode (this is important for things like dropout and batch normalization)

```python
model.eval()
```
- Run the model on the test data

```python
with torch.no_grad():
    output = model(input)
```
    Note: `with torch.no_grad():` is used to tell PyTorch not to calculate gradients during the forward pass. This is because we are not training the model, we are just evaluating it.

    Note: You will need to format your data in the same way as the training data.

- Print and visualise the results
- Compare the results to the ground truth

### Using the Model

These instructions are for PyTorch, but you can use any framework you like.

- Load the model
- Set the model to evaluation mode
- Run the model on an data from RoboSuite and your object detection algorithm
- Use the predicted position as an input to your PID controller


If you need extra explanation on PyTorch you can watch this video:
<div style="text-align: center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/OIenNRt2bjg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>