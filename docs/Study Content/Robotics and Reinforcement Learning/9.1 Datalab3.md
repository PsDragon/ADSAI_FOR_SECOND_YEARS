---
sort: 18
---
# PID with Vision

## Goal for the day:

- Develop a vision system using object detection to estimate the position of objects in a 3D environment.
- Integrate the PID controller with the vision system to control the position of the end effector of the robotic arm.

### Expected Output

- A model that can predict the position and yaw angle of objects in a 3D space
- A gif of a robot arm lifting locating and picking up an object, with vision data overlayed on the image

## General Plan:
- [ ] Discuss any questions about the knowledge modules so far
- [ ] Create a plan for collecting training data
- [ ] Collect training data for co-ordinate estimation
- [ ] Train a model to estimate the position of the cube
- [ ] Use the RoboSuite environment to simulate a robotic arm lifting a block, using a controller that you design that uses the vision system to estimate the position of the cube.

## Estimating the Position of a cube in a 3D Environment

### Collecting Training Data

Think about the following questions when planning how to collect training data:

- What is the input to the model? (Hint: What information about the objects would we have access to in the real world?)
- What is the output of the model? (Hint: what is the current input to the PID controller?)
- How much training data do we need?
- How should the data and labels be stored?

You can use the script that you created to collect image data from RoboSuite in Week 1 as a starting point.

### Creating a Model

These instructions are for PyTorch, but you can use any framework you like.

- Create a model class that inherits from `nn.Module`
- Define the layers of the model
- Define the forward pass

Here is an example of a model that takes in an image and some other features (bounding box coordinates and on-hot encoded object class) and outputs the position and yaw angle of the object in 3D space.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class Predictor(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 64, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(64, 128, 5)
        self.fc1 = nn.Linear(79360, 512)
        self.fc2 = nn.Linear(512, 64)
        #Add in the 8 additional object detection features: 4 for bounding box limits, for for 1 hot encoded class
        #e.g. for class 1: [xmin, ymin, xmax, ymax, 1, 0, 0, 0]
        #e.g. for class 3: [xmin, ymin, xmax, ymax, 0, 0, 1, 0]
        self.fc3 = nn.Linear(64+8, 32)
        #Final layer with 4 outputs (i.e. [x, y, z, yaw])
        self.fc4 = nn.Linear(32, 4)

    def forward(self, x, x2):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        concx = torch.cat((x,x2),dim=1) #concatenate the additional features
        x = F.relu(self.fc3(concx)) 
        x = self.fc4(x)
        return x
```
 You can use this model as a starting point and modify it to suit your needs. It can definitely be improved!

### Training a Model

These instructions are for PyTorch, but you can use any framework you like.
1. Create a model instance of the class you defined above

    ```python
    model = Predictor()
    ```
2. Create a loss function (Mean Squared Error is a good option for regression problems)

    ```python
    criterion = nn.MSELoss()
    ```
3. Create an optimizer (You may need to adjust the learning rate)

    ```python
    optimizer = optim.Adam(model.parameters(), lr=0.0001)
    ```
4. Load your training data (inputs) and labels (targets)

5. Fetch a batch of training data and labels (a btach size of 32 or 64 is a good place to start)

6. Zero gradients

    ```python
    optimizer.zero_grad()
    ```
7. Forward pass one batch

    ```python
    output = model(input) #if you have used the model above you will need two inputs
    ```
8. Calculate loss for the batch

    ```python
    loss = criterion(output, target)
    ```
9. Backward pass and step the optimizer - update weights

    ```python
    loss.backward()
    optimizer.step()
    ```
10. Print training statistics (Optional)

    ```python
    # print statistics
    running_loss += loss.item() #need to initialise running_loss = 0.0 before the loop
    if batch % 10 == 9:    # print every 10 batches
        print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / 10:.8f}')
        running_loss = 0.0
    ```
11. Repeat 5-10 until all batches have been processed
12. Repeat 11 for all epochs (10 is a good place to start)
13. Save the model
    
    ```python
    path = 'weights.pt'
    torch.save(model.state_dict(), path)
    print('Model state dictionary save as: ' + path)  
    ```

### Evaluating a Model

These instructions are for PyTorch, but you can use any framework you like.

- Create a model instance and load the weights

```python
model = Predictor()
state_dict = torch.load('weights.pt')
model.load_state_dict(state_dict)
```	

- Set the model to evaluation mode (this is important for things like dropout and batch normalization)

```python
model.eval()
```
- Run the model on the test data

```python
with torch.no_grad():
    output = model(input)
```
    Note: `with torch.no_grad():` is used to tell PyTorch not to calculate gradients during the forward pass. This is because we are not training the model, we are just evaluating it.

    Note: You will need to format your data in the same way as the training data.

- Print and visualise the results
- Compare the results to the ground truth

### Using the Model

These instructions are for PyTorch, but you can use any framework you like.

- Load the model
- Set the model to evaluation mode
- Run the model on an data from RoboSuite and your object detection algorithm
- Use the predicted position as an input to your PID controller


If you need extra explanation on PyTorch you can watch this video:
<div style="text-align: center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/OIenNRt2bjg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

## Adding Bounding Boxes and Text to Images

You can use the code below to add bounding boxes and text to images. This is useful for visualising the results of your object detection algorithm. If you save the images you can use them to create a gif to show your results.

```python	
from PIL import Image, ImageDraw

image = #your image
image = Image.fromarray(image)
xmin,ymin,xmax,ymax = (0,0,10,10)#your bounding box coordinates

ImageDraw.Draw(image).text((0, 80),'[x, y, z, yaw]',(0, 0, 0)) #add text (postion, text, colour)
ImageDraw.Draw(image).rectangle((xmin,ymin,xmax,ymax))
image = np.array(image)

plt.imsave('test.jpg', image)
```